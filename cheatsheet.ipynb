{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e61e1fd",
   "metadata": {},
   "source": [
    "## Run This Code First! This creates the Spark session and loads data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04d95750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9)\n",
      "Requirement already satisfied: delta-spark in c:\\users\\shubh\\appdata\\roaming\\python\\python38\\site-packages (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.10.0 in c:\\users\\shubh\\appdata\\roaming\\python\\python38\\site-packages (from delta-spark) (4.8.1)\n",
      "Requirement already satisfied: pyspark<3.2.0,>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from delta-spark) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.10.0->delta-spark) (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark<3.2.0,>=3.1.0->delta-spark) (0.10.9)\n",
      "Requirement already satisfied: money-parser in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: dateparser in c:\\users\\shubh\\appdata\\roaming\\python\\python38\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from dateparser) (2021.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from dateparser) (2021.4.4)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\shubh\\appdata\\roaming\\python\\python38\\site-packages (from dateparser) (3.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from dateparser) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->dateparser) (1.15.0)\n",
      "Requirement already satisfied: tzdata in c:\\programdata\\anaconda3\\lib\\site-packages (from tzlocal->dateparser) (2021.2.post0)\n",
      "Requirement already satisfied: backports.zoneinfo in c:\\users\\shubh\\appdata\\roaming\\python\\python38\\site-packages (from tzlocal->dateparser) (0.2.1)\n",
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyarrow) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark --user\n",
    "!pip install delta-spark --user\n",
    "!pip install money-parser --user\n",
    "!pip install dateparser --user\n",
    "!pip install pyarrow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2628c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from delta import *\n",
    "\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"jupyter\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"python\"\n",
    "# Create our Spark session and SQL Context.\n",
    "warehouse_path = abspath('spark-warehouse')\n",
    "builder = (\n",
    "    SparkSession.builder.master(\"local[4]\")\n",
    "    .config(\"spark.executor.memory\", \"2G\")\n",
    "    .config(\"spark.driver.memory\", \"2G\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_path)\n",
    "#    .config(\"spark.executor.heartbeatInterval\",\"1199s\")\n",
    "    .appName(\"cheatsheet\")\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).enableHiveSupport().getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "# Unmodified Auto dataset.\n",
    "auto_df = spark.read.format(\"csv\").option(\"header\", True).load(\"data/auto-mpg.csv\")\n",
    "\n",
    "# Fixed Auto dataset.\n",
    "auto_df_fixed = spark.read.format(\"csv\").option(\"header\", True).load(\"data/auto-mpg-fixed.csv\")\n",
    "for (column_name) in (\"mpg cylinders displacement horsepower weight acceleration\".split()):\n",
    "    auto_df_fixed = auto_df_fixed.withColumn(column_name, col(column_name).cast(\"double\"))\n",
    "auto_df_fixed = auto_df_fixed.withColumn(\"modelyear\", col(\"modelyear\").cast(\"int\"))\n",
    "auto_df_fixed = auto_df_fixed.withColumn(\"origin\", col(\"origin\").cast(\"int\"))\n",
    "\n",
    "# Cover type dataset.\n",
    "covtype_df = spark.read.format(\"parquet\").load(\"data/covtype.parquet\")\n",
    "for column_name in covtype_df.columns:\n",
    "    covtype_df = covtype_df.withColumn(column_name, col(column_name).cast(\"int\"))\n",
    "\n",
    "# Customer spend dataset.\n",
    "spend_df = spark.read.format(\"csv\").option(\"header\", True).load(\"data/customer_spend.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5a9b4",
   "metadata": {},
   "source": [
    "## Loading data stored in filesystems or databases, and saving it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add97889",
   "metadata": {},
   "source": [
    "**Load a DataFrame from CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26bfb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html\n",
    "# for a list of supported options.\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).load(\"data/auto-mpg.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15d86c",
   "metadata": {},
   "source": [
    "**Load a DataFrame from a Tab Separated Value (TSV) file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fd48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameReader.html\n",
    "# for a list of supported options.\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .load(\"data/auto-mpg.tsv\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5c0cb",
   "metadata": {},
   "source": [
    "**Save a DataFrame in CSV format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41cf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameWriter.html\n",
    "# for a list of supported options.\n",
    "auto_df.write.mode(\"overwrite\").csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b3088",
   "metadata": {},
   "source": [
    "**Load a DataFrame from Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28bf6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"data/auto-mpg.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687f21d",
   "metadata": {},
   "source": [
    "**Save a DataFrame in Parquet format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a73d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.write.mode(\"overwrite\").parquet(\"output.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11250a2d",
   "metadata": {},
   "source": [
    "**Load a DataFrame from JSON Lines (jsonl) Formatted Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb57da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+----------+--------------------+------+\n",
      "|              client|             country| session| timestamp|                 uri|  user|\n",
      "+--------------------+--------------------+--------+----------+--------------------+------+\n",
      "|{false, Mozilla/5...|          Bangladesh|55fa8213| 869196249|http://larson-har...|dde312|\n",
      "|{true, Mozilla/5....|                Niue|2fcd4a83|1031238717|http://hahn.com/p...|9d00b9|\n",
      "|{true, Mozilla/5....|              Rwanda|013b996e| 628683372|http://mann-cruz....|1339d4|\n",
      "|{false, Mozilla/5...|             Austria|07e8a71a|1043628668|https://www.jones...|966312|\n",
      "|{false, Mozilla/5...|              Belize|b23d05d8| 192738669|http://rose-colem...|2af1e1|\n",
      "|{false, Mozilla/5...|Lao People's Demo...|d83dfbae|1066490444|http://shepherd.c...|844395|\n",
      "|{false, Mozilla/5...|       French Guiana|e77dfaa2|1350920869|https://rose-wils...|  null|\n",
      "|{false, Mozilla/5...|Turks and Caicos ...|56664269| 280986223|http://owens-scot...|  null|\n",
      "|{false, Mozilla/5...|            Ethiopia|628d6059| 881914195|https://higgins.c...|8ab45a|\n",
      "|{false, Mozilla/5...|Saint Kitts and N...|85f9120c|1065114708|https://www.gordo...|  null|\n",
      "|{true, Mozilla/5....|                Niue|b582eb2d| 903885352|http://taylor.com...|  null|\n",
      "|{true, Mozilla/5....|          Mozambique|3a3a076a|1396767240|https://www.walke...|c9cfbc|\n",
      "|{false, Mozilla/5...|          Mauritania|f50b92bd| 846552008|  https://floyd.com/|4e612e|\n",
      "|{false, Mozilla/5...|          Bangladesh|b22d584c|1267210959|https://www.benso...|  null|\n",
      "|{true, Mozilla/5....|Syrian Arab Republic|b70a5779| 389952112|https://www.simon...|  null|\n",
      "|{false, Mozilla/5...|           Nicaragua|11cf53ff|1535167846|http://www.davis....|185348|\n",
      "|{false, Mozilla/5...|             Tokelau|8a020624| 864088605|http://www.galleg...|7a1c8e|\n",
      "|{false, Mozilla/5...|             Andorra|bbe09fd3| 315508192|http://www.johnso...|38cbc0|\n",
      "|{false, Mozilla/5...|           Guatemala|0824188a|   1989386|https://www.kelle...|f6804a|\n",
      "|{true, Mozilla/5....|            Guernsey|798f511a| 458479835|https://scott.com...|b2f5b0|\n",
      "+--------------------+--------------------+--------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON Lines / jsonl format uses one JSON document per line.\n",
    "# If you have data with mostly regular structure this is better than nesting it in an array.\n",
    "# See https://jsonlines.org/\n",
    "df = spark.read.json(\"data/weblog.jsonl\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64997e",
   "metadata": {},
   "source": [
    "**Save a DataFrame into a Hive catalog table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0e3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"autompg\")\n",
    "#auto_df.createOrReplaceTempView(\"autompg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d127b4d",
   "metadata": {},
   "source": [
    "**Load a Hive catalog table into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f02a471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the table previously saved.\n",
    "df = spark.table(\"autompg\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c6e34",
   "metadata": {},
   "source": [
    "## Special data handling scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66dc77",
   "metadata": {},
   "source": [
    "**Provide the schema when loading a DataFrame from CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b192d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0|3504.0|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0|3693.0|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0|3436.0|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0|3433.0|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0|3449.0|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0|4341.0|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0|4354.0|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0|4312.0|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0|4425.0|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0|3850.0|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0|3563.0|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0|3609.0|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0|3761.0|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0|3086.0|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|      95.0|2372.0|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|      95.0|2833.0|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|      97.0|2774.0|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|      85.0|2587.0|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|        97.0|      88.0|2130.0|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|        97.0|      46.0|1835.0|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/types.html\n",
    "# for a list of types.\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"mpg\", DoubleType(), True),\n",
    "        StructField(\"cylinders\", IntegerType(), True),\n",
    "        StructField(\"displacement\", DoubleType(), True),\n",
    "        StructField(\"horsepower\", DoubleType(), True),\n",
    "        StructField(\"weight\", DoubleType(), True),\n",
    "        StructField(\"acceleration\", DoubleType(), True),\n",
    "        StructField(\"modelyear\", IntegerType(), True),\n",
    "        StructField(\"origin\", IntegerType(), True),\n",
    "        StructField(\"carname\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .load(\"data/auto-mpg.csv\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e57a9",
   "metadata": {},
   "source": [
    "**Save a DataFrame to CSV, overwriting existing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6deffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.write.mode(\"overwrite\").csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4cefd",
   "metadata": {},
   "source": [
    "**Save a DataFrame to CSV with a header**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfd3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrameWriter.html\n",
    "# for a list of supported options.\n",
    "auto_df.coalesce(1).write.mode(\"overwrite\").csv(\"header.csv\", header=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ec476",
   "metadata": {},
   "source": [
    "**Save a DataFrame in a single CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c11ce8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.coalesce(1).write.mode(\"overwrite\").csv(\"single.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f8fc4",
   "metadata": {},
   "source": [
    "**Save DataFrame as a dynamic partitioned table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd95c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "auto_df.write.mode(\"append\").partitionBy(\"modelyear\").saveAsTable(\"autompg_partitioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17834c60",
   "metadata": {},
   "source": [
    "**Load a CSV file with a money column into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e083c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+\n",
      "|      date|customer_id|spend_dollars|\n",
      "+----------+-----------+-------------+\n",
      "|2020-01-31|          0|       0.0700|\n",
      "|2020-01-31|          1|       0.9800|\n",
      "|2020-01-31|          2|       0.0600|\n",
      "|2020-01-31|          3|       0.6500|\n",
      "|2020-01-31|          4|       0.5700|\n",
      "|2020-02-29|          0|       0.1000|\n",
      "|2020-02-29|          2|       4.4000|\n",
      "|2020-02-29|          3|       0.3900|\n",
      "|2020-02-29|          4|       2.1300|\n",
      "|2020-02-29|          5|       0.8200|\n",
      "|2020-02-29|          6|       1.3600|\n",
      "|2020-02-29|          7|       0.9300|\n",
      "|2020-03-31|          1|       0.0300|\n",
      "|2020-03-31|          2|       0.0800|\n",
      "|2020-03-31|          3|       1.0200|\n",
      "|2020-03-31|          5|       1.4100|\n",
      "|2020-03-31|          6|       3.2200|\n",
      "|2020-03-31|          7|       0.5600|\n",
      "|2020-03-31|          9|      17.5000|\n",
      "|2020-03-31|         10|       9.2800|\n",
      "+----------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DecimalType\n",
    "from decimal import Decimal\n",
    "\n",
    "# Load the text file.\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/customer_spend.csv\")\n",
    ")\n",
    "\n",
    "# Convert with a hardcoded custom UDF.\n",
    "money_udf = udf(lambda x: Decimal(x[1:].replace(\",\", \"\")), DecimalType(8, 4))\n",
    "money1 = df.withColumn(\"spend_dollars\", money_udf(df.spend_dollars))\n",
    "\n",
    "# Convert with the money_parser library (much safer).\n",
    "from money_parser import price_str\n",
    "\n",
    "money_convert = udf(\n",
    "    lambda x: Decimal(price_str(x)) if x is not None else None,\n",
    "    DecimalType(8, 4),\n",
    ")\n",
    "df = df.withColumn(\"spend_dollars\", money_convert(df.spend_dollars))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97e945",
   "metadata": {},
   "source": [
    "## Adding, removing and modifying DataFrame columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cecee7c",
   "metadata": {},
   "source": [
    "**Add a new column to a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7191ca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|               upper|               lower|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|CHEVROLET CHEVELL...|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|   BUICK SKYLARK 320|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|  PLYMOUTH SATELLITE|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|       AMC REBEL SST|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|         FORD TORINO|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|    FORD GALAXIE 500|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|    CHEVROLET IMPALA|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|   PLYMOUTH FURY III|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|    PONTIAC CATALINA|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|  AMC AMBASSADOR DPL|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se| DODGE CHALLENGER SE| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|  PLYMOUTH 'CUDA 340|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|CHEVROLET MONTE C...|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|BUICK ESTATE WAGO...|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|TOYOTA CORONA MAR...|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|     PLYMOUTH DUSTER|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|          AMC HORNET|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|       FORD MAVERICK|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|        DATSUN PL510|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|VOLKSWAGEN 1131 D...|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper, lower\n",
    "\n",
    "df = auto_df.withColumn(\"upper\", upper(auto_df.carname)).withColumn(\n",
    "    \"lower\", lower(auto_df.carname)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c606fbb",
   "metadata": {},
   "source": [
    "**Modify a DataFrame column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3589be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|     1970|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|     1970|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|     1970|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|     1970|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|     1970|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|     1970|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|     1970|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|     1970|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|     1970|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|     1970|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|     1970|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|     1970|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|     1970|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|     1970|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|     1970|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|     1970|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|     1970|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|     1970|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|     1970|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|     1970|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "df = auto_df.withColumn(\"modelyear\", concat(lit(\"19\"), col(\"modelyear\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c36dc",
   "metadata": {},
   "source": [
    "**Add a column with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03087b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|mpg_class|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|      low|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|      low|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|      low|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|      low|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|      low|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|      low|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|      low|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|      low|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|      low|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|      low|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|      low|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|      low|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|      low|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|      low|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|      mid|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|      mid|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|      low|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|      mid|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|      mid|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|      mid|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df = auto_df.withColumn(\n",
    "    \"mpg_class\",\n",
    "    when(col(\"mpg\") <= 20, \"low\")\n",
    "    .when(col(\"mpg\") <= 30, \"mid\")\n",
    "    .when(col(\"mpg\") <= 40, \"high\")\n",
    "    .otherwise(\"very high\"),\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79d65a",
   "metadata": {},
   "source": [
    "**Add a constant column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e92aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|one|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|  1|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|  1|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|  1|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|  1|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|  1|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|  1|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|  1|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|  1|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|  1|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|  1|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|  1|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|  1|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|  1|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|  1|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|  1|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|  1|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|  1|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|  1|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|  1|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|  1|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df = auto_df.withColumn(\"one\", lit(1))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8697879",
   "metadata": {},
   "source": [
    "**Concatenate columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "960c6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|concatenated|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|      8_18.0|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|      8_15.0|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|      8_18.0|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|      8_16.0|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|      8_17.0|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|      8_15.0|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|      8_14.0|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|      8_14.0|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|      8_14.0|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|      8_15.0|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|      8_15.0|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|      8_14.0|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|      8_15.0|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|      8_14.0|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|      4_24.0|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|      6_22.0|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|      6_18.0|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|      6_21.0|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|      4_27.0|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|      4_26.0|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "df = auto_df.withColumn(\n",
    "    \"concatenated\", concat(col(\"cylinders\"), lit(\"_\"), col(\"mpg\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588f7a5",
   "metadata": {},
   "source": [
    "**Drop a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e5ef685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.drop(\"horsepower\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d78f66",
   "metadata": {},
   "source": [
    "**Change a column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "513f2851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horses|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0| 130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0| 165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0| 150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0| 150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0| 140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0| 198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0| 220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0| 215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0| 225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0| 190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0| 170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0| 160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0| 150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0| 225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0| 95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0| 95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0| 97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0| 85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00| 88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00| 46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.withColumnRenamed(\"horsepower\", \"horses\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035055aa",
   "metadata": {},
   "source": [
    "**Change multiple column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaa7c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+------+------+------------+----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horses|weight|acceleration|year|origin|             carname|\n",
      "+----+---------+------------+------+------+------------+----+------+--------------------+\n",
      "|18.0|        8|       307.0| 130.0| 3504.|        12.0|  70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0| 165.0| 3693.|        11.5|  70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0| 150.0| 3436.|        11.0|  70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0| 150.0| 3433.|        12.0|  70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0| 140.0| 3449.|        10.5|  70|     1|         ford torino|\n",
      "|15.0|        8|       429.0| 198.0| 4341.|        10.0|  70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0| 220.0| 4354.|         9.0|  70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0| 215.0| 4312.|         8.5|  70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0| 225.0| 4425.|        10.0|  70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0| 190.0| 3850.|         8.5|  70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0| 170.0| 3563.|        10.0|  70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0| 160.0| 3609.|         8.0|  70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0| 150.0| 3761.|         9.5|  70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0| 225.0| 3086.|        10.0|  70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0| 95.00| 2372.|        15.0|  70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0| 95.00| 2833.|        15.5|  70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0| 97.00| 2774.|        15.5|  70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0| 85.00| 2587.|        16.0|  70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00| 88.00| 2130.|        14.5|  70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00| 46.00| 1835.|        20.5|  70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+------+------+------------+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.withColumnRenamed(\"horsepower\", \"horses\").withColumnRenamed(\n",
    "    \"modelyear\", \"year\"\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588f6f4",
   "metadata": {},
   "source": [
    "**Convert a DataFrame column to a Python list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95cefa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chevrolet chevelle malibu', 'buick skylark 320', 'plymouth satellite', 'amc rebel sst', 'ford torino', 'ford galaxie 500', 'chevrolet impala', 'plymouth fury iii', 'pontiac catalina', 'amc ambassador dpl']\n"
     ]
    }
   ],
   "source": [
    "names = auto_df.select(\"carname\").rdd.flatMap(lambda x: x).collect()\n",
    "print(str(names[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddbc91",
   "metadata": {},
   "source": [
    "**Convert a scalar query to a Python value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9421e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.514572864321615\n"
     ]
    }
   ],
   "source": [
    "average = auto_df.agg(dict(mpg=\"avg\")).first()[0]\n",
    "print(str(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b116a1",
   "metadata": {},
   "source": [
    "**Consume a DataFrame row-wise as Python dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca99c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mpg': '18.0', 'cylinders': '8', 'displacement': '307.0', 'horsepower': '130.0', 'weight': '3504.', 'acceleration': '12.0', 'modelyear': '70', 'origin': '1', 'carname': 'chevrolet chevelle malibu'}\n",
      "{'mpg': '15.0', 'cylinders': '8', 'displacement': '350.0', 'horsepower': '165.0', 'weight': '3693.', 'acceleration': '11.5', 'modelyear': '70', 'origin': '1', 'carname': 'buick skylark 320'}\n",
      "{'mpg': '18.0', 'cylinders': '8', 'displacement': '318.0', 'horsepower': '150.0', 'weight': '3436.', 'acceleration': '11.0', 'modelyear': '70', 'origin': '1', 'carname': 'plymouth satellite'}\n"
     ]
    }
   ],
   "source": [
    "first_three = auto_df.limit(3)\n",
    "for row in first_three.collect():\n",
    "    my_dict = row.asDict()\n",
    "    print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1831a",
   "metadata": {},
   "source": [
    "**Select particular columns from a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60687eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+\n",
      "| mpg|cylinders|displacement|\n",
      "+----+---------+------------+\n",
      "|18.0|        8|       307.0|\n",
      "|15.0|        8|       350.0|\n",
      "|18.0|        8|       318.0|\n",
      "|16.0|        8|       304.0|\n",
      "|17.0|        8|       302.0|\n",
      "|15.0|        8|       429.0|\n",
      "|14.0|        8|       454.0|\n",
      "|14.0|        8|       440.0|\n",
      "|14.0|        8|       455.0|\n",
      "|15.0|        8|       390.0|\n",
      "|15.0|        8|       383.0|\n",
      "|14.0|        8|       340.0|\n",
      "|15.0|        8|       400.0|\n",
      "|14.0|        8|       455.0|\n",
      "|24.0|        4|       113.0|\n",
      "|22.0|        6|       198.0|\n",
      "|18.0|        6|       199.0|\n",
      "|21.0|        6|       200.0|\n",
      "|27.0|        4|       97.00|\n",
      "|26.0|        4|       97.00|\n",
      "+----+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.select([\"mpg\", \"cylinders\", \"displacement\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc57a0c",
   "metadata": {},
   "source": [
    "**Create an empty dataframe with a specified schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e51478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|my_id|my_string|\n",
      "+-----+---------+\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, LongType, StringType\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"my_id\", LongType(), True),\n",
    "        StructField(\"my_string\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "df = spark.createDataFrame([], schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc20b8f",
   "metadata": {},
   "source": [
    "**Create a constant dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbf26fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------------------+\n",
      "|my_id|my_string|       my_timestamp|\n",
      "+-----+---------+-------------------+\n",
      "|    1|      foo|2021-01-01 00:00:00|\n",
      "|    2|      bar|2021-01-02 00:00:00|\n",
      "+-----+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql.types import (\n",
    "    StructField,\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"my_id\", LongType(), True),\n",
    "        StructField(\"my_string\", StringType(), True),\n",
    "        StructField(\"my_timestamp\", TimestampType(), True),\n",
    "    ]\n",
    ")\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, \"foo\", datetime.datetime.strptime(\"2021-01-01\", \"%Y-%m-%d\")),\n",
    "        (2, \"bar\", datetime.datetime.strptime(\"2021-01-02\", \"%Y-%m-%d\")),\n",
    "    ],\n",
    "    schema,\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f339975",
   "metadata": {},
   "source": [
    "**Convert String to Double**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4392651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|      95.0| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|      95.0| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|      97.0| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|      85.0| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|      88.0| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|      46.0| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.withColumn(\"horsepower\", col(\"horsepower\").cast(\"double\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0040c4",
   "metadata": {},
   "source": [
    "**Convert String to Integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "631d5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|       130| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|       165| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|       150| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|       150| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|       140| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|       198| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|       220| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|       215| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|       225| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|       190| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|       170| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|       160| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|       150| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|       225| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|        95| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|        95| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|        97| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|        85| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|        88| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|        46| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.withColumn(\"horsepower\", col(\"horsepower\").cast(\"int\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aef1d2",
   "metadata": {},
   "source": [
    "**Get the size of a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50864022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 rows\n",
      "9 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"{} rows\".format(auto_df.count()))\n",
    "print(\"{} columns\".format(len(auto_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f61a8",
   "metadata": {},
   "source": [
    "**Get a DataFrame's number of partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0625773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 partition(s)\n"
     ]
    }
   ],
   "source": [
    "print(\"{} partition(s)\".format(auto_df.rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c1e36",
   "metadata": {},
   "source": [
    "**Get data types of a DataFrame's columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e5e3172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mpg', 'string'), ('cylinders', 'string'), ('displacement', 'string'), ('horsepower', 'string'), ('weight', 'string'), ('acceleration', 'string'), ('modelyear', 'string'), ('origin', 'string'), ('carname', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(auto_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ee37a",
   "metadata": {},
   "source": [
    "**Convert an RDD to Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9127533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "|     mpg|cylinders|displacement|horsepower|    weight|acceleration|modelyear|origin|             carname|\n",
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "|18.018.0|       88|  307.0307.0|130.0130.0|3504.3504.|    12.012.0|     7070|    11|chevrolet chevell...|\n",
      "|15.015.0|       88|  350.0350.0|165.0165.0|3693.3693.|    11.511.5|     7070|    11|buick skylark 320...|\n",
      "|18.018.0|       88|  318.0318.0|150.0150.0|3436.3436.|    11.011.0|     7070|    11|plymouth satellit...|\n",
      "|16.016.0|       88|  304.0304.0|150.0150.0|3433.3433.|    12.012.0|     7070|    11|amc rebel sstamc ...|\n",
      "|17.017.0|       88|  302.0302.0|140.0140.0|3449.3449.|    10.510.5|     7070|    11|ford torinoford t...|\n",
      "|15.015.0|       88|  429.0429.0|198.0198.0|4341.4341.|    10.010.0|     7070|    11|ford galaxie 500f...|\n",
      "|14.014.0|       88|  454.0454.0|220.0220.0|4354.4354.|      9.09.0|     7070|    11|chevrolet impalac...|\n",
      "|14.014.0|       88|  440.0440.0|215.0215.0|4312.4312.|      8.58.5|     7070|    11|plymouth fury iii...|\n",
      "|14.014.0|       88|  455.0455.0|225.0225.0|4425.4425.|    10.010.0|     7070|    11|pontiac catalinap...|\n",
      "|15.015.0|       88|  390.0390.0|190.0190.0|3850.3850.|      8.58.5|     7070|    11|amc ambassador dp...|\n",
      "|15.015.0|       88|  383.0383.0|170.0170.0|3563.3563.|    10.010.0|     7070|    11|dodge challenger ...|\n",
      "|14.014.0|       88|  340.0340.0|160.0160.0|3609.3609.|      8.08.0|     7070|    11|plymouth 'cuda 34...|\n",
      "|15.015.0|       88|  400.0400.0|150.0150.0|3761.3761.|      9.59.5|     7070|    11|chevrolet monte c...|\n",
      "|14.014.0|       88|  455.0455.0|225.0225.0|3086.3086.|    10.010.0|     7070|    11|buick estate wago...|\n",
      "|24.024.0|       44|  113.0113.0|95.0095.00|2372.2372.|    15.015.0|     7070|    33|toyota corona mar...|\n",
      "|22.022.0|       66|  198.0198.0|95.0095.00|2833.2833.|    15.515.5|     7070|    11|plymouth dusterpl...|\n",
      "|18.018.0|       66|  199.0199.0|97.0097.00|2774.2774.|    15.515.5|     7070|    11|amc hornetamc hornet|\n",
      "|21.021.0|       66|  200.0200.0|85.0085.00|2587.2587.|    16.016.0|     7070|    11|ford maverickford...|\n",
      "|27.027.0|       44|  97.0097.00|88.0088.00|2130.2130.|    14.514.5|     7070|    33|datsun pl510datsu...|\n",
      "|26.026.0|       44|  97.0097.00|46.0046.00|1835.1835.|    20.520.5|     7070|    22|volkswagen 1131 d...|\n",
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# First, get the RDD from the DataFrame.\n",
    "rdd = auto_df.rdd\n",
    "\n",
    "# This converts it back to an RDD with no changes.\n",
    "df = rdd.map(lambda x: Row(**x.asDict())).toDF()\n",
    "\n",
    "# This changes the rows before creating the DataFrame.\n",
    "df = rdd.map(\n",
    "    lambda x: Row(**{k: v * 2 for (k, v) in x.asDict().items()})\n",
    ").toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf1bce",
   "metadata": {},
   "source": [
    "**Print the contents of an RDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "600a1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(mpg='18.0', cylinders='8', displacement='307.0', horsepower='130.0', weight='3504.', acceleration='12.0', modelyear='70', origin='1', carname='chevrolet chevelle malibu'), Row(mpg='15.0', cylinders='8', displacement='350.0', horsepower='165.0', weight='3693.', acceleration='11.5', modelyear='70', origin='1', carname='buick skylark 320'), Row(mpg='18.0', cylinders='8', displacement='318.0', horsepower='150.0', weight='3436.', acceleration='11.0', modelyear='70', origin='1', carname='plymouth satellite'), Row(mpg='16.0', cylinders='8', displacement='304.0', horsepower='150.0', weight='3433.', acceleration='12.0', modelyear='70', origin='1', carname='amc rebel sst'), Row(mpg='17.0', cylinders='8', displacement='302.0', horsepower='140.0', weight='3449.', acceleration='10.5', modelyear='70', origin='1', carname='ford torino'), Row(mpg='15.0', cylinders='8', displacement='429.0', horsepower='198.0', weight='4341.', acceleration='10.0', modelyear='70', origin='1', carname='ford galaxie 500'), Row(mpg='14.0', cylinders='8', displacement='454.0', horsepower='220.0', weight='4354.', acceleration='9.0', modelyear='70', origin='1', carname='chevrolet impala'), Row(mpg='14.0', cylinders='8', displacement='440.0', horsepower='215.0', weight='4312.', acceleration='8.5', modelyear='70', origin='1', carname='plymouth fury iii'), Row(mpg='14.0', cylinders='8', displacement='455.0', horsepower='225.0', weight='4425.', acceleration='10.0', modelyear='70', origin='1', carname='pontiac catalina'), Row(mpg='15.0', cylinders='8', displacement='390.0', horsepower='190.0', weight='3850.', acceleration='8.5', modelyear='70', origin='1', carname='amc ambassador dpl')]\n"
     ]
    }
   ],
   "source": [
    "rdd = auto_df.rdd\n",
    "print(rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55280506",
   "metadata": {},
   "source": [
    "**Print the contents of a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5feef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "|     mpg|cylinders|displacement|horsepower|    weight|acceleration|modelyear|origin|             carname|\n",
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "|18.018.0|       88|  307.0307.0|130.0130.0|3504.3504.|    12.012.0|     7070|    11|chevrolet chevell...|\n",
      "|15.015.0|       88|  350.0350.0|165.0165.0|3693.3693.|    11.511.5|     7070|    11|buick skylark 320...|\n",
      "|18.018.0|       88|  318.0318.0|150.0150.0|3436.3436.|    11.011.0|     7070|    11|plymouth satellit...|\n",
      "|16.016.0|       88|  304.0304.0|150.0150.0|3433.3433.|    12.012.0|     7070|    11|amc rebel sstamc ...|\n",
      "|17.017.0|       88|  302.0302.0|140.0140.0|3449.3449.|    10.510.5|     7070|    11|ford torinoford t...|\n",
      "|15.015.0|       88|  429.0429.0|198.0198.0|4341.4341.|    10.010.0|     7070|    11|ford galaxie 500f...|\n",
      "|14.014.0|       88|  454.0454.0|220.0220.0|4354.4354.|      9.09.0|     7070|    11|chevrolet impalac...|\n",
      "|14.014.0|       88|  440.0440.0|215.0215.0|4312.4312.|      8.58.5|     7070|    11|plymouth fury iii...|\n",
      "|14.014.0|       88|  455.0455.0|225.0225.0|4425.4425.|    10.010.0|     7070|    11|pontiac catalinap...|\n",
      "|15.015.0|       88|  390.0390.0|190.0190.0|3850.3850.|      8.58.5|     7070|    11|amc ambassador dp...|\n",
      "|15.015.0|       88|  383.0383.0|170.0170.0|3563.3563.|    10.010.0|     7070|    11|dodge challenger ...|\n",
      "|14.014.0|       88|  340.0340.0|160.0160.0|3609.3609.|      8.08.0|     7070|    11|plymouth 'cuda 34...|\n",
      "|15.015.0|       88|  400.0400.0|150.0150.0|3761.3761.|      9.59.5|     7070|    11|chevrolet monte c...|\n",
      "|14.014.0|       88|  455.0455.0|225.0225.0|3086.3086.|    10.010.0|     7070|    11|buick estate wago...|\n",
      "|24.024.0|       44|  113.0113.0|95.0095.00|2372.2372.|    15.015.0|     7070|    33|toyota corona mar...|\n",
      "|22.022.0|       66|  198.0198.0|95.0095.00|2833.2833.|    15.515.5|     7070|    11|plymouth dusterpl...|\n",
      "|18.018.0|       66|  199.0199.0|97.0097.00|2774.2774.|    15.515.5|     7070|    11|amc hornetamc hornet|\n",
      "|21.021.0|       66|  200.0200.0|85.0085.00|2587.2587.|    16.016.0|     7070|    11|ford maverickford...|\n",
      "|27.027.0|       44|  97.0097.00|88.0088.00|2130.2130.|    14.514.5|     7070|    33|datsun pl510datsu...|\n",
      "|26.026.0|       44|  97.0097.00|46.0046.00|1835.1835.|    20.520.5|     7070|    22|volkswagen 1131 d...|\n",
      "+--------+---------+------------+----------+----------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto_df.show(10)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00c6f3",
   "metadata": {},
   "source": [
    "**Process each row of a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83cc5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def foreach_function(row):\n",
    "    if row.horsepower is not None:\n",
    "        os.system(\"echo \" + row.horsepower)\n",
    "\n",
    "auto_df.foreach(foreach_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e613d0a",
   "metadata": {},
   "source": [
    "**DataFrame Map example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ac4cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|    _1|\n",
      "+------+\n",
      "|1300.0|\n",
      "|1650.0|\n",
      "|1500.0|\n",
      "|1500.0|\n",
      "|1400.0|\n",
      "|1980.0|\n",
      "|2200.0|\n",
      "|2150.0|\n",
      "|2250.0|\n",
      "|1900.0|\n",
      "|1700.0|\n",
      "|1600.0|\n",
      "|1500.0|\n",
      "|2250.0|\n",
      "| 950.0|\n",
      "| 950.0|\n",
      "| 970.0|\n",
      "| 850.0|\n",
      "| 880.0|\n",
      "| 460.0|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_function(row):\n",
    "    if row.horsepower is not None:\n",
    "        return [float(row.horsepower) * 10]\n",
    "    else:\n",
    "        return [None]\n",
    "\n",
    "df = auto_df.rdd.map(map_function).toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392e6a6",
   "metadata": {},
   "source": [
    "**DataFrame Flatmap example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e8e8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|val|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import Row\n",
    "\n",
    "def flatmap_function(row):\n",
    "    if row.cylinders is not None:\n",
    "        return list(range(int(row.cylinders)))\n",
    "    else:\n",
    "        return [None]\n",
    "\n",
    "rdd = auto_df.rdd.flatMap(flatmap_function)\n",
    "row = Row(\"val\")\n",
    "df = rdd.map(row).toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7fb04",
   "metadata": {},
   "source": [
    "**Create a custom UDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d502a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|manufacturer|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|   chevrolet|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|       buick|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|    plymouth|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|         amc|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|        ford|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|        ford|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|   chevrolet|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|    plymouth|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|     pontiac|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|         amc|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|       dodge|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|    plymouth|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|   chevrolet|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|       buick|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|      toyota|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|    plymouth|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|         amc|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|        ford|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|      datsun|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|  volkswagen|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df.withColumn(\"manufacturer\", first_word_udf(auto_df.carname))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42139e9",
   "metadata": {},
   "source": [
    "## Data conversions and other modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1991d446",
   "metadata": {},
   "source": [
    "**Extract data from a string using a regular expression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72dd25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             carname|identifier|\n",
      "+--------------------+----------+\n",
      "|chevrolet chevell...|          |\n",
      "|   buick skylark 320|       320|\n",
      "|  plymouth satellite|          |\n",
      "|       amc rebel sst|          |\n",
      "|         ford torino|          |\n",
      "|    ford galaxie 500|       500|\n",
      "|    chevrolet impala|          |\n",
      "|   plymouth fury iii|          |\n",
      "|    pontiac catalina|          |\n",
      "|  amc ambassador dpl|          |\n",
      "| dodge challenger se|          |\n",
      "|  plymouth 'cuda 340|       340|\n",
      "|chevrolet monte c...|          |\n",
      "|buick estate wago...|          |\n",
      "|toyota corona mar...|          |\n",
      "|     plymouth duster|          |\n",
      "|          amc hornet|          |\n",
      "|       ford maverick|          |\n",
      "|        datsun pl510|      l510|\n",
      "|volkswagen 1131 d...|      1131|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract\n",
    "\n",
    "group = 0\n",
    "df = (\n",
    "    auto_df.withColumn(\n",
    "        \"identifier\", regexp_extract(col(\"carname\"), \"(\\S?\\d+)\", group)\n",
    "    )\n",
    "    .drop(\"acceleration\")\n",
    "    .drop(\"cylinders\")\n",
    "    .drop(\"displacement\")\n",
    "    .drop(\"modelyear\")\n",
    "    .drop(\"mpg\")\n",
    "    .drop(\"origin\")\n",
    "    .drop(\"horsepower\")\n",
    "    .drop(\"weight\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b2520",
   "metadata": {},
   "source": [
    "**Fill NULL values in specific columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fb71e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.fillna({\"horsepower\": 0})\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16a012",
   "metadata": {},
   "source": [
    "**Fill NULL values with column average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37fdac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df = auto_df.fillna({\"horsepower\": auto_df.agg(avg(\"horsepower\")).first()[0]})\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeca1f8",
   "metadata": {},
   "source": [
    "**Fill NULL values with group average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb8cca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+------+------------+---------+------+--------------------+----------+\n",
      "| mpg|cylinders|displacement|weight|acceleration|modelyear|origin|             carname|horsepower|\n",
      "+----+---------+------------+------+------------+---------+------+--------------------+----------+\n",
      "|18.0|        8|       307.0| 3504.|        12.0|       70|     1|chevrolet chevell...|     130.0|\n",
      "|15.0|        8|       350.0| 3693.|        11.5|       70|     1|   buick skylark 320|     165.0|\n",
      "|18.0|        8|       318.0| 3436.|        11.0|       70|     1|  plymouth satellite|     150.0|\n",
      "|16.0|        8|       304.0| 3433.|        12.0|       70|     1|       amc rebel sst|     150.0|\n",
      "|17.0|        8|       302.0| 3449.|        10.5|       70|     1|         ford torino|     140.0|\n",
      "|15.0|        8|       429.0| 4341.|        10.0|       70|     1|    ford galaxie 500|     198.0|\n",
      "|14.0|        8|       454.0| 4354.|         9.0|       70|     1|    chevrolet impala|     220.0|\n",
      "|14.0|        8|       440.0| 4312.|         8.5|       70|     1|   plymouth fury iii|     215.0|\n",
      "|14.0|        8|       455.0| 4425.|        10.0|       70|     1|    pontiac catalina|     225.0|\n",
      "|15.0|        8|       390.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|     190.0|\n",
      "|15.0|        8|       383.0| 3563.|        10.0|       70|     1| dodge challenger se|     170.0|\n",
      "|14.0|        8|       340.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|     160.0|\n",
      "|15.0|        8|       400.0| 3761.|         9.5|       70|     1|chevrolet monte c...|     150.0|\n",
      "|14.0|        8|       455.0| 3086.|        10.0|       70|     1|buick estate wago...|     225.0|\n",
      "|24.0|        4|       113.0| 2372.|        15.0|       70|     3|toyota corona mar...|     95.00|\n",
      "|22.0|        6|       198.0| 2833.|        15.5|       70|     1|     plymouth duster|     95.00|\n",
      "|18.0|        6|       199.0| 2774.|        15.5|       70|     1|          amc hornet|     97.00|\n",
      "|21.0|        6|       200.0| 2587.|        16.0|       70|     1|       ford maverick|     85.00|\n",
      "|27.0|        4|       97.00| 2130.|        14.5|       70|     3|        datsun pl510|     88.00|\n",
      "|26.0|        4|       97.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|     46.00|\n",
      "+----+---------+------------+------+------------+---------+------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "\n",
    "unmodified_columns = auto_df.columns\n",
    "unmodified_columns.remove(\"horsepower\")\n",
    "manufacturer_avg = auto_df.groupBy(\"cylinders\").agg({\"horsepower\": \"avg\"})\n",
    "df = auto_df.join(manufacturer_avg, \"cylinders\").select(\n",
    "    *unmodified_columns,\n",
    "    coalesce(\"horsepower\", \"avg(horsepower)\").alias(\"horsepower\"),\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e87b5",
   "metadata": {},
   "source": [
    "**Unpack a DataFrame's JSON column to a new DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d86581ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| id| c0| c1|\n",
      "+---+---+---+\n",
      "|  1| 10| 11|\n",
      "|  2| 20| 21|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, json_tuple\n",
    "\n",
    "source = spark.sparkContext.parallelize(\n",
    "    [[\"1\", '{ \"a\" : 10, \"b\" : 11 }'], [\"2\", '{ \"a\" : 20, \"b\" : 21 }']]\n",
    ").toDF([\"id\", \"json\"])\n",
    "df = source.select(\"id\", json_tuple(col(\"json\"), \"a\", \"b\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3162869",
   "metadata": {},
   "source": [
    "**Query a JSON column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "085d03b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| id|  a|  b|\n",
      "+---+---+---+\n",
      "|  2| 20| 21|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, json_tuple\n",
    "\n",
    "source = spark.sparkContext.parallelize(\n",
    "    [[\"1\", '{ \"a\" : 10, \"b\" : 11 }'], [\"2\", '{ \"a\" : 20, \"b\" : 21 }']]\n",
    ").toDF([\"id\", \"json\"])\n",
    "df = (\n",
    "    source.select(\"id\", json_tuple(col(\"json\"), \"a\", \"b\"))\n",
    "    .withColumnRenamed(\"c0\", \"a\")\n",
    "    .withColumnRenamed(\"c1\", \"b\")\n",
    "    .where(col(\"b\") > 15)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc229c",
   "metadata": {},
   "source": [
    "## Filtering, sorting, removing duplicates and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d35d88",
   "metadata": {},
   "source": [
    "**Filter a column using a condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5347457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|            hi 1200d|\n",
      "|30.0|        4|       79.00|     70.00| 2074.|        19.5|       71|     2|         peugeot 304|\n",
      "|30.0|        4|       88.00|     76.00| 2065.|        14.5|       71|     2|           fiat 124b|\n",
      "|31.0|        4|       71.00|     65.00| 1773.|        19.0|       71|     3| toyota corolla 1200|\n",
      "|35.0|        4|       72.00|     69.00| 1613.|        18.0|       71|     3|         datsun 1200|\n",
      "|31.0|        4|       79.00|     67.00| 1950.|        19.0|       74|     3|         datsun b210|\n",
      "|32.0|        4|       71.00|     65.00| 1836.|        21.0|       74|     3| toyota corolla 1200|\n",
      "|31.0|        4|       76.00|     52.00| 1649.|        16.5|       74|     3|       toyota corona|\n",
      "|32.0|        4|       83.00|     61.00| 2003.|        19.0|       74|     3|          datsun 710|\n",
      "|31.0|        4|       79.00|     67.00| 2000.|        16.0|       74|     2|           fiat x1.9|\n",
      "|33.0|        4|       91.00|     53.00| 1795.|        17.5|       75|     3|    honda civic cvcc|\n",
      "|33.0|        4|       91.00|     53.00| 1795.|        17.4|       76|     3|         honda civic|\n",
      "|32.0|        4|       85.00|     70.00| 1990.|        17.0|       76|     3|        datsun b-210|\n",
      "|31.5|        4|       98.00|     68.00| 2045.|        18.5|       77|     3|   honda accord cvcc|\n",
      "|30.0|        4|       111.0|     80.00| 2155.|        14.8|       77|     1|buick opel isuzu ...|\n",
      "|36.0|        4|       79.00|     58.00| 1825.|        18.6|       77|     2|       renault 5 gtl|\n",
      "|33.5|        4|       85.00|     70.00| 1945.|        16.8|       77|     3|datsun f-10 hatch...|\n",
      "|30.5|        4|       98.00|     63.00| 2051.|        17.0|       77|     1|  chevrolet chevette|\n",
      "|33.5|        4|       98.00|     83.00| 2075.|        15.9|       77|     1|      dodge colt m/m|\n",
      "|30.0|        4|       97.00|     67.00| 1985.|        16.4|       77|     3|           subaru dl|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.filter(col(\"mpg\") > \"30\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5674d5",
   "metadata": {},
   "source": [
    "**Filter based on a specific column value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cbdbfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|10.0|        8|       360.0|     215.0| 4615.|        14.0|       70|     1|           ford f250|\n",
      "|10.0|        8|       307.0|     200.0| 4376.|        15.0|       70|     1|           chevy c20|\n",
      "|11.0|        8|       318.0|     210.0| 4382.|        13.5|       70|     1|          dodge d200|\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|            hi 1200d|\n",
      "|14.0|        8|       350.0|     165.0| 4209.|        12.0|       71|     1|    chevrolet impala|\n",
      "|14.0|        8|       400.0|     175.0| 4464.|        11.5|       71|     1|pontiac catalina ...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.where(col(\"cylinders\") == \"8\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b54d2c",
   "metadata": {},
   "source": [
    "**Filter based on an IN list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaece02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "|25.0|        4|       110.0|     87.00| 2672.|        17.5|       70|     2|         peugeot 504|\n",
      "|24.0|        4|       107.0|     90.00| 2430.|        14.5|       70|     2|         audi 100 ls|\n",
      "|25.0|        4|       104.0|     95.00| 2375.|        17.5|       70|     2|            saab 99e|\n",
      "|26.0|        4|       121.0|     113.0| 2234.|        12.5|       70|     2|            bmw 2002|\n",
      "|21.0|        6|       199.0|     90.00| 2648.|        15.0|       70|     1|         amc gremlin|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       71|     3|        datsun pl510|\n",
      "|28.0|        4|       140.0|     90.00| 2264.|        15.5|       71|     1| chevrolet vega 2300|\n",
      "|25.0|        4|       113.0|     95.00| 2228.|        14.0|       71|     3|       toyota corona|\n",
      "|25.0|        4|       98.00|      null| 2046.|        19.0|       71|     1|          ford pinto|\n",
      "|19.0|        6|       232.0|     100.0| 2634.|        13.0|       71|     1|         amc gremlin|\n",
      "|16.0|        6|       225.0|     105.0| 3439.|        15.5|       71|     1|plymouth satellit...|\n",
      "|17.0|        6|       250.0|     100.0| 3329.|        15.5|       71|     1|chevrolet chevell...|\n",
      "|19.0|        6|       250.0|     88.00| 3302.|        15.5|       71|     1|     ford torino 500|\n",
      "|18.0|        6|       232.0|     100.0| 3288.|        15.5|       71|     1|         amc matador|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.where(col(\"cylinders\").isin([\"4\", \"6\"]))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4483d0",
   "metadata": {},
   "source": [
    "**Filter based on a NOT IN list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab1d6e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|10.0|        8|       360.0|     215.0| 4615.|        14.0|       70|     1|           ford f250|\n",
      "|10.0|        8|       307.0|     200.0| 4376.|        15.0|       70|     1|           chevy c20|\n",
      "|11.0|        8|       318.0|     210.0| 4382.|        13.5|       70|     1|          dodge d200|\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|            hi 1200d|\n",
      "|14.0|        8|       350.0|     165.0| 4209.|        12.0|       71|     1|    chevrolet impala|\n",
      "|14.0|        8|       400.0|     175.0| 4464.|        11.5|       71|     1|pontiac catalina ...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.where(~col(\"cylinders\").isin([\"4\", \"6\"]))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc6949",
   "metadata": {},
   "source": [
    "**Filter values based on keys in another DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89a1b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Our DataFrame of keys to exclude.\n",
    "exclude_keys = auto_df.select(\n",
    "    (col(\"modelyear\") + 1).alias(\"adjusted_year\")\n",
    ").distinct()\n",
    "\n",
    "# The anti join returns only keys with no matches.\n",
    "filtered = auto_df.join(\n",
    "    exclude_keys,\n",
    "    how=\"left_anti\",\n",
    "    on=auto_df.modelyear == exclude_keys.adjusted_year,\n",
    ")\n",
    "\n",
    "# Alternatively we can register a temporary table and use a SQL expression.\n",
    "exclude_keys.registerTempTable(\"exclude_keys\")\n",
    "df = auto_df.filter(\n",
    "    \"modelyear not in ( select adjusted_year from exclude_keys )\"\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c46d98",
   "metadata": {},
   "source": [
    "**Get Dataframe rows that match a substring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3185124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|16.0|        6|       225.0|     105.0| 3439.|        15.5|       71|     1|plymouth satellit...|\n",
      "|13.0|        8|       350.0|     155.0| 4502.|        13.5|       72|     1|buick lesabre custom|\n",
      "|14.0|        8|       318.0|     150.0| 4077.|        14.0|       72|     1|plymouth satellit...|\n",
      "|15.0|        8|       318.0|     150.0| 3777.|        12.5|       73|     1|dodge coronet custom|\n",
      "|12.0|        8|       455.0|     225.0| 4951.|        11.0|       73|     1|buick electra 225...|\n",
      "|16.0|        6|       250.0|     100.0| 3278.|        18.0|       73|     1|chevrolet nova cu...|\n",
      "|13.0|        8|       360.0|     170.0| 4654.|        13.0|       73|     1|plymouth custom s...|\n",
      "|15.0|        8|       318.0|     150.0| 3399.|        11.0|       73|     1|   dodge dart custom|\n",
      "|14.0|        8|       318.0|     150.0| 4457.|        13.5|       74|     1|dodge coronet cus...|\n",
      "|19.0|        6|       225.0|     95.00| 3264.|        16.0|       75|     1|plymouth valiant ...|\n",
      "|19.0|        6|       225.0|     100.0| 3630.|        17.7|       77|     1|plymouth volare c...|\n",
      "|29.0|        4|       97.00|     78.00| 1940.|        14.5|       77|     2|volkswagen rabbit...|\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|\n",
      "|31.9|        4|       89.00|     71.00| 1925.|        14.0|       79|     2|    vw rabbit custom|\n",
      "|35.7|        4|       98.00|     80.00| 1915.|        14.4|       79|     1|dodge colt hatchb...|\n",
      "|37.3|        4|       91.00|     69.00| 2130.|        14.7|       79|     2|  fiat strada custom|\n",
      "|37.0|        4|       91.00|     68.00| 2025.|        18.2|       82|     3|  mazda glc custom l|\n",
      "|31.0|        4|       91.00|     68.00| 1970.|        17.6|       82|     3|    mazda glc custom|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.where(auto_df.carname.contains(\"custom\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500d3e2",
   "metadata": {},
   "source": [
    "**Filter a Dataframe based on a custom substring search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab7af9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|16.0|        6|       225.0|     105.0| 3439.|        15.5|       71|     1|plymouth satellit...|\n",
      "|13.0|        8|       350.0|     155.0| 4502.|        13.5|       72|     1|buick lesabre custom|\n",
      "|14.0|        8|       318.0|     150.0| 4077.|        14.0|       72|     1|plymouth satellit...|\n",
      "|15.0|        8|       318.0|     150.0| 3777.|        12.5|       73|     1|dodge coronet custom|\n",
      "|12.0|        8|       455.0|     225.0| 4951.|        11.0|       73|     1|buick electra 225...|\n",
      "|16.0|        6|       250.0|     100.0| 3278.|        18.0|       73|     1|chevrolet nova cu...|\n",
      "|13.0|        8|       360.0|     170.0| 4654.|        13.0|       73|     1|plymouth custom s...|\n",
      "|15.0|        8|       318.0|     150.0| 3399.|        11.0|       73|     1|   dodge dart custom|\n",
      "|14.0|        8|       318.0|     150.0| 4457.|        13.5|       74|     1|dodge coronet cus...|\n",
      "|19.0|        6|       225.0|     95.00| 3264.|        16.0|       75|     1|plymouth valiant ...|\n",
      "|19.0|        6|       225.0|     100.0| 3630.|        17.7|       77|     1|plymouth volare c...|\n",
      "|29.0|        4|       97.00|     78.00| 1940.|        14.5|       77|     2|volkswagen rabbit...|\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|\n",
      "|31.9|        4|       89.00|     71.00| 1925.|        14.0|       79|     2|    vw rabbit custom|\n",
      "|35.7|        4|       98.00|     80.00| 1915.|        14.4|       79|     1|dodge colt hatchb...|\n",
      "|37.3|        4|       91.00|     69.00| 2130.|        14.7|       79|     2|  fiat strada custom|\n",
      "|37.0|        4|       91.00|     68.00| 2025.|        18.2|       82|     3|  mazda glc custom l|\n",
      "|31.0|        4|       91.00|     68.00| 1970.|        17.6|       82|     3|    mazda glc custom|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.where(col(\"carname\").like(\"%custom%\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c21a70",
   "metadata": {},
   "source": [
    "**Filter based on a column's length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05e2043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+-----------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|    carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+-----------+\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|ford torino|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1| amc hornet|\n",
      "|25.0|        4|       110.0|     87.00| 2672.|        17.5|       70|     2|peugeot 504|\n",
      "|24.0|        4|       107.0|     90.00| 2430.|        14.5|       70|     2|audi 100 ls|\n",
      "|25.0|        4|       104.0|     95.00| 2375.|        17.5|       70|     2|   saab 99e|\n",
      "|26.0|        4|       121.0|     113.0| 2234.|        12.5|       70|     2|   bmw 2002|\n",
      "|21.0|        6|       199.0|     90.00| 2648.|        15.0|       70|     1|amc gremlin|\n",
      "|10.0|        8|       360.0|     215.0| 4615.|        14.0|       70|     1|  ford f250|\n",
      "|10.0|        8|       307.0|     200.0| 4376.|        15.0|       70|     1|  chevy c20|\n",
      "|11.0|        8|       318.0|     210.0| 4382.|        13.5|       70|     1| dodge d200|\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|   hi 1200d|\n",
      "|25.0|        4|       98.00|      null| 2046.|        19.0|       71|     1| ford pinto|\n",
      "|19.0|        6|       232.0|     100.0| 2634.|        13.0|       71|     1|amc gremlin|\n",
      "|18.0|        6|       232.0|     100.0| 3288.|        15.5|       71|     1|amc matador|\n",
      "|28.0|        4|       116.0|     90.00| 2123.|        14.0|       71|     2|  opel 1900|\n",
      "|30.0|        4|       79.00|     70.00| 2074.|        19.5|       71|     2|peugeot 304|\n",
      "|30.0|        4|       88.00|     76.00| 2065.|        14.5|       71|     2|  fiat 124b|\n",
      "|35.0|        4|       72.00|     69.00| 1613.|        18.0|       71|     3|datsun 1200|\n",
      "|14.0|        8|       304.0|     150.0| 3672.|        11.5|       73|     1|amc matador|\n",
      "|13.0|        8|       351.0|     158.0| 4363.|        13.0|       73|     1|   ford ltd|\n",
      "+----+---------+------------+----------+------+------------+---------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length\n",
    "\n",
    "df = auto_df.where(length(col(\"carname\")) < 12)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391bcf6",
   "metadata": {},
   "source": [
    "**Multiple filter conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abf7ac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+----------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|         carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+----------------+\n",
      "|32.7|        6|       168.0|     132.0| 2910.|        11.4|       80|     3|   datsun 280-zx|\n",
      "|30.0|        4|       135.0|     84.00| 2385.|        12.9|       81|     1|plymouth reliant|\n",
      "|32.0|        4|       135.0|     84.00| 2295.|        11.6|       82|     1|   dodge rampage|\n",
      "+----+---------+------------+----------+------+------------+---------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# OR\n",
    "df = auto_df.filter(\n",
    "    (col(\"mpg\") > \"30\") | (col(\"acceleration\") < \"10\")\n",
    ")\n",
    "# AND\n",
    "df = auto_df.filter(\n",
    "    (col(\"mpg\") > \"30\") & (col(\"acceleration\") < \"13\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b138d1",
   "metadata": {},
   "source": [
    "**Sort DataFrame by a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37b77832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|31.9|        4|       89.00|     71.00| 1925.|        14.0|       79|     2|    vw rabbit custom|\n",
      "|44.3|        4|       90.00|     48.00| 2085.|        21.7|       80|     2|vw rabbit c (diesel)|\n",
      "|29.0|        4|       90.00|     70.00| 1937.|        14.2|       76|     2|           vw rabbit|\n",
      "|41.5|        4|       98.00|     76.00| 2144.|        14.7|       80|     2|           vw rabbit|\n",
      "|44.0|        4|       97.00|     52.00| 2130.|        24.6|       82|     2|           vw pickup|\n",
      "|43.4|        4|       90.00|     48.00| 2335.|        23.7|       80|     2|  vw dasher (diesel)|\n",
      "|30.7|        6|       145.0|     76.00| 3160.|        19.6|       81|     2|        volvo diesel|\n",
      "|17.0|        6|       163.0|     125.0| 3140.|        13.6|       78|     2|         volvo 264gl|\n",
      "|20.0|        4|       130.0|     102.0| 3150.|        15.7|       76|     2|           volvo 245|\n",
      "|22.0|        4|       121.0|     98.00| 2945.|        14.5|       75|     2|         volvo 244dl|\n",
      "|18.0|        4|       121.0|     112.0| 2933.|        14.5|       72|     2|     volvo 145e (sw)|\n",
      "|19.0|        4|       121.0|     112.0| 2868.|        15.5|       73|     2|         volvo 144ea|\n",
      "|23.0|        4|       97.00|     54.00| 2254.|        23.5|       72|     2|   volkswagen type 3|\n",
      "|26.0|        4|       97.00|     46.00| 1950.|        21.0|       73|     2|volkswagen super ...|\n",
      "|31.5|        4|       89.00|     71.00| 1990.|        14.9|       78|     2| volkswagen scirocco|\n",
      "|36.0|        4|       105.0|     74.00| 1980.|        15.3|       82|     2| volkswagen rabbit l|\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|\n",
      "|29.0|        4|       97.00|     78.00| 1940.|        14.5|       77|     2|volkswagen rabbit...|\n",
      "|29.0|        4|       90.00|     70.00| 1937.|        14.0|       75|     2|   volkswagen rabbit|\n",
      "|29.5|        4|       97.00|     71.00| 1825.|        12.2|       76|     2|   volkswagen rabbit|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.orderBy(\"carname\")\n",
    "df = auto_df.orderBy(col(\"carname\").desc())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca46afd",
   "metadata": {},
   "source": [
    "**Take the first N rows of a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a57d3bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "df = auto_df.limit(n)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91c7ef",
   "metadata": {},
   "source": [
    "**Get distinct values of a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99c13a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|cylinders|\n",
      "+---------+\n",
      "|        3|\n",
      "|        8|\n",
      "|        5|\n",
      "|        6|\n",
      "|        4|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.select(\"cylinders\").distinct()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e84f61",
   "metadata": {},
   "source": [
    "**Remove duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33aedab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|24.0|        4|       107.0|     90.00| 2430.|        14.5|       70|     2|         audi 100 ls|\n",
      "|32.0|        4|       135.0|     84.00| 2295.|        11.6|       82|     1|       dodge rampage|\n",
      "|24.5|        4|       151.0|     88.00| 2740.|        16.0|       77|     1|pontiac sunbird c...|\n",
      "|13.0|        8|       350.0|     145.0| 3988.|        13.0|       73|     1|    chevrolet malibu|\n",
      "|15.0|        8|       350.0|     145.0| 4082.|        13.0|       73|     1|chevrolet monte c...|\n",
      "|16.0|        8|       351.0|     149.0| 4335.|        14.5|       77|     1|    ford thunderbird|\n",
      "|32.9|        4|       119.0|     100.0| 2615.|        14.8|       81|     3|        datsun 200sx|\n",
      "|34.1|        4|       86.00|     65.00| 1975.|        15.2|       79|     3|    maxda glc deluxe|\n",
      "|22.0|        4|       121.0|     98.00| 2945.|        14.5|       75|     2|         volvo 244dl|\n",
      "|18.0|        6|       232.0|     100.0| 3288.|        15.5|       71|     1|         amc matador|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|30.9|        4|       105.0|     75.00| 2230.|        14.5|       78|     1|          dodge omni|\n",
      "|13.0|        8|       302.0|     130.0| 3870.|        15.0|       76|     1|           ford f108|\n",
      "|13.0|        8|       302.0|     140.0| 4294.|        16.0|       72|     1|ford gran torino ...|\n",
      "|27.2|        4|       119.0|     97.00| 2300.|        14.7|       78|     3|          datsun 510|\n",
      "|16.2|        6|       163.0|     133.0| 3410.|        15.8|       78|     2|       peugeot 604sl|\n",
      "|16.0|        6|       225.0|     105.0| 3439.|        15.5|       71|     1|plymouth satellit...|\n",
      "|18.2|        8|       318.0|     135.0| 3830.|        15.2|       79|     1|     dodge st. regis|\n",
      "|30.0|        4|       88.00|     76.00| 2065.|        14.5|       71|     2|           fiat 124b|\n",
      "|31.5|        4|       98.00|     68.00| 2045.|        18.5|       77|     3|   honda accord cvcc|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = auto_df.dropDuplicates([\"carname\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f4217",
   "metadata": {},
   "source": [
    "## Group DataFrame data by key to perform aggregates like counting, sums, averages, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a0951",
   "metadata": {},
   "source": [
    "**count(*) on a particular column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0630cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|cylinders|count|\n",
      "+---------+-----+\n",
      "|        4|  204|\n",
      "|        8|  103|\n",
      "|        6|   84|\n",
      "|        3|    4|\n",
      "|        5|    3|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# No sorting.\n",
    "df = auto_df.groupBy(\"cylinders\").count()\n",
    "\n",
    "# With sorting.\n",
    "df = auto_df.groupBy(\"cylinders\").count().orderBy(desc(\"count\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256148d5",
   "metadata": {},
   "source": [
    "**Group and sort**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ed9a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|cylinders|    avg_horsepower|\n",
      "+---------+------------------+\n",
      "|        8| 158.3009708737864|\n",
      "|        6|101.50602409638554|\n",
      "|        3|             99.25|\n",
      "|        5| 82.33333333333333|\n",
      "|        4| 78.28140703517587|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, desc\n",
    "\n",
    "df = (\n",
    "    auto_df.groupBy(\"cylinders\")\n",
    "    .agg(avg(\"horsepower\").alias(\"avg_horsepower\"))\n",
    "    .orderBy(desc(\"avg_horsepower\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84009eb5",
   "metadata": {},
   "source": [
    "**Filter groups based on an aggregate value, equivalent to SQL HAVING clause**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcade0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|cylinders|count|\n",
      "+---------+-----+\n",
      "|        4|  204|\n",
      "|        8|  103|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "df = (\n",
    "    auto_df.groupBy(\"cylinders\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .filter(col(\"count\") > 100)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2155fd",
   "metadata": {},
   "source": [
    "**Group by multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ea0ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+\n",
      "|modelyear|cylinders|    avg_horsepower|\n",
      "+---------+---------+------------------+\n",
      "|       70|        8|183.66666666666666|\n",
      "|       73|        8|             170.0|\n",
      "|       71|        8|166.85714285714286|\n",
      "|       72|        8|159.69230769230768|\n",
      "|       77|        8|           152.375|\n",
      "|       76|        8|146.33333333333334|\n",
      "|       74|        8|             146.0|\n",
      "|       75|        8|             142.0|\n",
      "|       78|        8|             135.5|\n",
      "|       79|        8|             131.9|\n",
      "|       80|        6|             111.0|\n",
      "|       77|        3|             110.0|\n",
      "|       78|        6|109.83333333333333|\n",
      "|       81|        8|             105.0|\n",
      "|       79|        6|             105.0|\n",
      "|       78|        5|             103.0|\n",
      "|       82|        6|102.33333333333333|\n",
      "|       73|        6|           102.125|\n",
      "|       77|        6|             102.0|\n",
      "|       74|        6|101.66666666666667|\n",
      "+---------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, desc\n",
    "\n",
    "df = (\n",
    "    auto_df.groupBy([\"modelyear\", \"cylinders\"])\n",
    "    .agg(avg(\"horsepower\").alias(\"avg_horsepower\"))\n",
    "    .orderBy(desc(\"avg_horsepower\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d4a9",
   "metadata": {},
   "source": [
    "**Aggregate multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54168298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------+-----------------+\n",
      "|modelyear|   avg(horsepower)|max(weight)|max(displacement)|\n",
      "+---------+------------------+-----------+-----------------+\n",
      "|       73|           130.475|      4997.|            98.00|\n",
      "|       71|107.03703703703704|      5140.|            98.00|\n",
      "|       70|147.82758620689654|      4732.|            97.00|\n",
      "|       75|101.06666666666666|      4668.|            97.00|\n",
      "|       78| 99.69444444444444|      4080.|            98.00|\n",
      "|       77|105.07142857142857|      4335.|            98.00|\n",
      "|       82| 81.46666666666667|      3035.|            98.00|\n",
      "|       81| 81.03571428571429|      3725.|            98.00|\n",
      "|       79|101.20689655172414|      4360.|            98.00|\n",
      "|       72|120.17857142857143|      4633.|            98.00|\n",
      "|       74| 94.23076923076923|      4699.|            98.00|\n",
      "|       76|101.11764705882354|      4380.|            98.00|\n",
      "|       80| 77.48148148148148|      3381.|            98.00|\n",
      "+---------+------------------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expressions = dict(horsepower=\"avg\", weight=\"max\", displacement=\"max\")\n",
    "df = auto_df.groupBy(\"modelyear\").agg(expressions)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e3d2b",
   "metadata": {},
   "source": [
    "**Aggregate multiple columns with custom orderings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaa14bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------+-----------------+\n",
      "|modelyear|   avg(horsepower)|max(weight)|max(displacement)|\n",
      "+---------+------------------+-----------+-----------------+\n",
      "|       73|           130.475|      4997.|            98.00|\n",
      "|       72|120.17857142857143|      4633.|            98.00|\n",
      "|       71|107.03703703703704|      5140.|            98.00|\n",
      "|       77|105.07142857142857|      4335.|            98.00|\n",
      "|       79|101.20689655172414|      4360.|            98.00|\n",
      "|       76|101.11764705882354|      4380.|            98.00|\n",
      "|       78| 99.69444444444444|      4080.|            98.00|\n",
      "|       74| 94.23076923076923|      4699.|            98.00|\n",
      "|       82| 81.46666666666667|      3035.|            98.00|\n",
      "|       81| 81.03571428571429|      3725.|            98.00|\n",
      "|       80| 77.48148148148148|      3381.|            98.00|\n",
      "|       70|147.82758620689654|      4732.|            97.00|\n",
      "|       75|101.06666666666666|      4668.|            97.00|\n",
      "+---------+------------------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, desc_nulls_last\n",
    "\n",
    "expressions = dict(horsepower=\"avg\", weight=\"max\", displacement=\"max\")\n",
    "orderings = [\n",
    "    desc_nulls_last(\"max(displacement)\"),\n",
    "    desc_nulls_last(\"avg(horsepower)\"),\n",
    "    asc(\"max(weight)\"),\n",
    "]\n",
    "df = auto_df.groupBy(\"modelyear\").agg(expressions).orderBy(*orderings)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d015fa1",
   "metadata": {},
   "source": [
    "**Get the maximum of a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebd2984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|max_horsepower|\n",
      "+--------------+\n",
      "|         98.00|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "\n",
    "df = auto_df.select(max(col(\"horsepower\")).alias(\"max_horsepower\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc88d0",
   "metadata": {},
   "source": [
    "**Sum a list of columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b89e038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+--------------+\n",
      "|         sum(mpg)|sum(weight)|sum(cylinders)|\n",
      "+-----------------+-----------+--------------+\n",
      "|9358.800000000003|  1182229.0|        2171.0|\n",
      "+-----------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exprs = {x: \"sum\" for x in (\"weight\", \"cylinders\", \"mpg\")}\n",
    "df = auto_df.agg(exprs)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e7f9e",
   "metadata": {},
   "source": [
    "**Sum a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a9542cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|cylinders|total_weight|\n",
      "+---------+------------+\n",
      "|        3|      9594.0|\n",
      "|        8|    423816.0|\n",
      "|        5|      9310.0|\n",
      "|        6|    268651.0|\n",
      "|        4|    470858.0|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df = auto_df.groupBy(\"cylinders\").agg(sum(\"weight\").alias(\"total_weight\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65602681",
   "metadata": {},
   "source": [
    "**Aggregate all numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e26033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+--------------+-----------------+---------------+-----------------+\n",
      "|sum(weight)|sum(acceleration)|sum(cylinders)|         sum(mpg)|sum(horsepower)|sum(displacement)|\n",
      "+-----------+-----------------+--------------+-----------------+---------------+-----------------+\n",
      "|  1182229.0|6196.099999999994|        2171.0|9358.800000000003|        40952.0|          76983.5|\n",
      "+-----------+-----------------+--------------+-----------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerics = set([\"decimal\", \"double\", \"float\", \"integer\", \"long\", \"short\"])\n",
    "exprs = {x[0]: \"sum\" for x in auto_df_fixed.dtypes if x[1] in numerics}\n",
    "df = auto_df_fixed.agg(exprs)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039444ac",
   "metadata": {},
   "source": [
    "**Count unique after grouping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b27b8244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|cylinders|count(mpg)|\n",
      "+---------+----------+\n",
      "|        3|         4|\n",
      "|        8|        27|\n",
      "|        5|         3|\n",
      "|        6|        38|\n",
      "|        4|        87|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df = auto_df.groupBy(\"cylinders\").agg(countDistinct(\"mpg\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d4a79",
   "metadata": {},
   "source": [
    "**Count distinct values on all columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26091d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+--------------+\n",
      "|count(mpg)|count(cylinders)|count(displacement)|count(horsepower)|count(weight)|count(acceleration)|count(modelyear)|count(origin)|count(carname)|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+--------------+\n",
      "|       129|               5|                 82|               93|          351|                 96|              13|            3|           305|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df = auto_df.agg(*(countDistinct(c) for c in auto_df.columns))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c2758",
   "metadata": {},
   "source": [
    "**Group by then filter on the count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "711b0ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|cylinders|count|\n",
      "+---------+-----+\n",
      "|        8|  103|\n",
      "|        4|  204|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.groupBy(\"cylinders\").count().where(col(\"count\") > 100)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb11cd1",
   "metadata": {},
   "source": [
    "**Find the top N per row group (use N=1 for maximum)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "012a1579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname| rn|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "|21.5|        3|       80.00|     110.0| 2720.|        13.5|       77|     3|          mazda rx-4|  1|\n",
      "|23.7|        3|       70.00|     100.0| 2420.|        12.5|       80|     3|       mazda rx-7 gs|  2|\n",
      "|19.0|        3|       70.00|      97.0| 2330.|        13.5|       72|     3|     mazda rx2 coupe|  3|\n",
      "|18.0|        3|       70.00|      90.0| 2124.|        13.5|       73|     3|           maxda rx3|  4|\n",
      "|16.0|        8|       400.0|     230.0| 4278.|        9.50|       73|     1|  pontiac grand prix|  1|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|  2|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|  3|\n",
      "|12.0|        8|       455.0|     225.0| 4951.|        11.0|       73|     1|buick electra 225...|  4|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|  5|\n",
      "|20.3|        5|       131.0|     103.0| 2830.|        15.9|       78|     2|           audi 5000|  1|\n",
      "|25.4|        5|       183.0|      77.0| 3530.|        20.1|       79|     2|  mercedes benz 300d|  2|\n",
      "|36.4|        5|       121.0|      67.0| 2950.|        19.9|       80|     2| audi 5000s (diesel)|  3|\n",
      "|17.7|        6|       231.0|     165.0| 3445.|        13.4|       78|     1|buick regal sport...|  1|\n",
      "|16.2|        6|       163.0|     133.0| 3410.|        15.8|       78|     2|       peugeot 604sl|  2|\n",
      "|32.7|        6|       168.0|     132.0| 2910.|        11.4|       80|     3|       datsun 280-zx|  3|\n",
      "|17.0|        6|       163.0|     125.0| 3140.|        13.6|       78|     2|         volvo 264gl|  4|\n",
      "|20.0|        6|       156.0|     122.0| 2807.|        13.5|       73|     3|      toyota mark ii|  5|\n",
      "|25.0|        4|       121.0|     115.0| 2671.|        13.5|       75|     2|           saab 99le|  1|\n",
      "|21.6|        4|       121.0|     115.0| 2795.|        15.7|       78|     2|          saab 99gle|  2|\n",
      "|26.0|        4|       121.0|     113.0| 2234.|        12.5|       70|     2|            bmw 2002|  3|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# To get the maximum per group, set n=1.\n",
    "n = 5\n",
    "w = Window().partitionBy(\"cylinders\").orderBy(col(\"horsepower\").desc())\n",
    "df = (\n",
    "    auto_df.withColumn(\"horsepower\", col(\"horsepower\").cast(\"double\"))\n",
    "    .withColumn(\"rn\", row_number().over(w))\n",
    "    .where(col(\"rn\") <= n)\n",
    "    .select(\"*\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180a747",
   "metadata": {},
   "source": [
    "**Group key/values into a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9bece5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|cylinders|              models|\n",
      "+---------+--------------------+\n",
      "|        3|[mazda rx2 coupe,...|\n",
      "|        8|[chevrolet chevel...|\n",
      "|        5|[audi 5000, merce...|\n",
      "|        6|[plymouth duster,...|\n",
      "|        4|[toyota corona ma...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, collect_list\n",
    "\n",
    "df = auto_df.groupBy(\"cylinders\").agg(\n",
    "    collect_list(col(\"carname\")).alias(\"models\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd50942",
   "metadata": {},
   "source": [
    "**Compute a histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4bd3870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([46.0, 62.72727272727273, 79.45454545454545, 96.18181818181819, 112.9090909090909, 129.63636363636363, 146.36363636363637, 163.0909090909091, 179.8181818181818, 196.54545454545453, 213.27272727272725, 230.0], [23, 89, 102, 65, 17, 27, 32, 15, 9, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Target column must be numeric.\n",
    "df = auto_df.withColumn(\"horsepower\", col(\"horsepower\").cast(\"double\"))\n",
    "\n",
    "# N is the number of bins.\n",
    "N = 11\n",
    "histogram = df.select(\"horsepower\").rdd.flatMap(lambda x: x).histogram(N)\n",
    "print(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd2068",
   "metadata": {},
   "source": [
    "**Compute global percentiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9d8dfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|ntile4|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|            hi 1200d|     1|\n",
      "|46.6|        4|       86.00|     65.00| 2110.|        17.9|       80|     3|           mazda glc|     1|\n",
      "|44.6|        4|       91.00|     67.00| 1850.|        13.8|       80|     3| honda civic 1500 gl|     1|\n",
      "|44.3|        4|       90.00|     48.00| 2085.|        21.7|       80|     2|vw rabbit c (diesel)|     1|\n",
      "|44.0|        4|       97.00|     52.00| 2130.|        24.6|       82|     2|           vw pickup|     1|\n",
      "|43.4|        4|       90.00|     48.00| 2335.|        23.7|       80|     2|  vw dasher (diesel)|     1|\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|     1|\n",
      "|41.5|        4|       98.00|     76.00| 2144.|        14.7|       80|     2|           vw rabbit|     1|\n",
      "|40.9|        4|       85.00|      null| 1835.|        17.3|       80|     2|renault lecar deluxe|     1|\n",
      "|40.8|        4|       85.00|     65.00| 2110.|        19.2|       80|     3|          datsun 210|     1|\n",
      "|39.4|        4|       85.00|     70.00| 2070.|        18.6|       78|     3|      datsun b210 gx|     1|\n",
      "|39.1|        4|       79.00|     58.00| 1755.|        16.9|       81|     3|      toyota starlet|     1|\n",
      "|39.0|        4|       86.00|     64.00| 1875.|        16.4|       81|     1|      plymouth champ|     1|\n",
      "|38.1|        4|       89.00|     60.00| 1968.|        18.8|       80|     3|toyota corolla te...|     1|\n",
      "|38.0|        4|       105.0|     63.00| 2125.|        14.7|       82|     1|plymouth horizon ...|     1|\n",
      "|38.0|        4|       91.00|     67.00| 1965.|        15.0|       82|     3|         honda civic|     1|\n",
      "|38.0|        4|       91.00|     67.00| 1995.|        16.2|       82|     3|       datsun 310 gx|     1|\n",
      "|38.0|        6|       262.0|     85.00| 3015.|        17.0|       82|     1|oldsmobile cutlas...|     1|\n",
      "|37.7|        4|       89.00|     62.00| 2050.|        17.3|       81|     3|       toyota tercel|     1|\n",
      "|37.3|        4|       91.00|     69.00| 2130.|        14.7|       79|     2|  fiat strada custom|     1|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, ntile\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window().orderBy(col(\"mpg\").desc())\n",
    "df = auto_df.withColumn(\"ntile4\", ntile(4).over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cf49e",
   "metadata": {},
   "source": [
    "**Compute percentiles within a partition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb345bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|ntile4|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "|23.7|        3|       70.00|     100.0| 2420.|        12.5|       80|     3|       mazda rx-7 gs|     1|\n",
      "|21.5|        3|       80.00|     110.0| 2720.|        13.5|       77|     3|          mazda rx-4|     2|\n",
      "|19.0|        3|       70.00|     97.00| 2330.|        13.5|       72|     3|     mazda rx2 coupe|     3|\n",
      "|18.0|        3|       70.00|     90.00| 2124.|        13.5|       73|     3|           maxda rx3|     4|\n",
      "| 9.0|        8|       304.0|     193.0| 4732.|        18.5|       70|     1|            hi 1200d|     1|\n",
      "|26.6|        8|       350.0|     105.0| 3725.|        19.0|       81|     1|oldsmobile cutlas...|     1|\n",
      "|23.9|        8|       260.0|     90.00| 3420.|        22.2|       79|     1|oldsmobile cutlas...|     1|\n",
      "|23.0|        8|       350.0|     125.0| 3900.|        17.4|       79|     1|   cadillac eldorado|     1|\n",
      "|20.2|        8|       302.0|     139.0| 3570.|        12.8|       78|     1|mercury monarch ghia|     1|\n",
      "|20.0|        8|       262.0|     110.0| 3221.|        13.5|       75|     1| chevrolet monza 2+2|     1|\n",
      "|19.9|        8|       260.0|     110.0| 3365.|        15.5|       78|     1|oldsmobile cutlas...|     1|\n",
      "|19.4|        8|       318.0|     140.0| 3735.|        13.2|       78|     1|      dodge diplomat|     1|\n",
      "|19.2|        8|       305.0|     145.0| 3425.|        13.2|       78|     1|chevrolet monte c...|     1|\n",
      "|19.2|        8|       267.0|     125.0| 3605.|        15.0|       79|     1|chevrolet malibu ...|     1|\n",
      "|18.5|        8|       360.0|     150.0| 3940.|        13.0|       79|     1|chrysler lebaron ...|     1|\n",
      "|18.2|        8|       318.0|     135.0| 3830.|        15.2|       79|     1|     dodge st. regis|     1|\n",
      "|18.1|        8|       302.0|     139.0| 3205.|        11.2|       78|     1|         ford futura|     1|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|     1|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|     1|\n",
      "|17.6|        8|       302.0|     129.0| 3725.|        13.4|       79|     1|     ford ltd landau|     1|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, ntile\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window().partitionBy(\"cylinders\").orderBy(col(\"mpg\").desc())\n",
    "df = auto_df.withColumn(\"ntile4\", ntile(4).over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458b091",
   "metadata": {},
   "source": [
    "**Compute percentiles after aggregating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a38e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|modelyear|count|ntile4|\n",
      "+---------+-----+------+\n",
      "|       73|   40|     1|\n",
      "|       78|   36|     1|\n",
      "|       76|   34|     1|\n",
      "|       82|   31|     1|\n",
      "|       75|   30|     2|\n",
      "|       70|   29|     2|\n",
      "|       81|   29|     2|\n",
      "|       79|   29|     3|\n",
      "|       80|   29|     3|\n",
      "|       71|   28|     3|\n",
      "|       77|   28|     4|\n",
      "|       72|   28|     4|\n",
      "|       74|   27|     4|\n",
      "+---------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, ntile\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "grouped = auto_df.groupBy(\"modelyear\").count()\n",
    "w = Window().orderBy(col(\"count\").desc())\n",
    "df = grouped.withColumn(\"ntile4\", ntile(4).over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c1eaa",
   "metadata": {},
   "source": [
    "**Filter rows with values below a target percentile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3efb0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|35.0|        4|       72.00|     69.00| 1613.|        18.0|       71|     3|         datsun 1200|\n",
      "|36.0|        4|       79.00|     58.00| 1825.|        18.6|       77|     2|       renault 5 gtl|\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|\n",
      "|36.1|        4|       98.00|     66.00| 1800.|        14.4|       78|     1|         ford fiesta|\n",
      "|39.4|        4|       85.00|     70.00| 2070.|        18.6|       78|     3|      datsun b210 gx|\n",
      "|36.1|        4|       91.00|     60.00| 1800.|        16.4|       78|     3|    honda civic cvcc|\n",
      "|35.7|        4|       98.00|     80.00| 1915.|        14.4|       79|     1|dodge colt hatchb...|\n",
      "|34.5|        4|       105.0|     70.00| 2150.|        14.9|       79|     1|plymouth horizon tc3|\n",
      "|37.3|        4|       91.00|     69.00| 2130.|        14.7|       79|     2|  fiat strada custom|\n",
      "|41.5|        4|       98.00|     76.00| 2144.|        14.7|       80|     2|           vw rabbit|\n",
      "|38.1|        4|       89.00|     60.00| 1968.|        18.8|       80|     3|toyota corolla te...|\n",
      "|37.2|        4|       86.00|     65.00| 2019.|        16.4|       80|     3|          datsun 310|\n",
      "|37.0|        4|       119.0|     92.00| 2434.|        15.0|       80|     3|datsun 510 hatchback|\n",
      "|46.6|        4|       86.00|     65.00| 2110.|        17.9|       80|     3|           mazda glc|\n",
      "|40.8|        4|       85.00|     65.00| 2110.|        19.2|       80|     3|          datsun 210|\n",
      "|44.3|        4|       90.00|     48.00| 2085.|        21.7|       80|     2|vw rabbit c (diesel)|\n",
      "|43.4|        4|       90.00|     48.00| 2335.|        23.7|       80|     2|  vw dasher (diesel)|\n",
      "|36.4|        5|       121.0|     67.00| 2950.|        19.9|       80|     2| audi 5000s (diesel)|\n",
      "|44.6|        4|       91.00|     67.00| 1850.|        13.8|       80|     3| honda civic 1500 gl|\n",
      "|40.9|        4|       85.00|      null| 1835.|        17.3|       80|     2|renault lecar deluxe|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "target_percentile = auto_df.agg(\n",
    "    F.expr(\"percentile(mpg, 0.9)\").alias(\"target_percentile\")\n",
    ").first()[0]\n",
    "df = auto_df.filter(col(\"mpg\") > lit(target_percentile))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01d681",
   "metadata": {},
   "source": [
    "**Aggregate and rollup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cffc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+-----+\n",
      "|modelyear|cylinders|    avg_horsepower|count|\n",
      "+---------+---------+------------------+-----+\n",
      "|       82|        6|102.33333333333333|    3|\n",
      "|       82|        4| 79.14814814814815|   28|\n",
      "|       82|     null| 81.46666666666667|   31|\n",
      "|       81|        8|             105.0|    1|\n",
      "|       81|        6|100.71428571428571|    7|\n",
      "|       81|        4|             72.95|   21|\n",
      "|       81|     null| 81.03571428571429|   29|\n",
      "|       80|        6|             111.0|    2|\n",
      "|       80|        5|              67.0|    1|\n",
      "|       80|        4| 74.04347826086956|   25|\n",
      "|       80|        3|             100.0|    1|\n",
      "|       80|     null| 77.48148148148148|   29|\n",
      "|     null|     null| 80.05882352941177|   89|\n",
      "+---------+---------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, count, desc\n",
    "\n",
    "subset = auto_df.filter(col(\"modelyear\") > 79)\n",
    "df = (\n",
    "    subset.rollup(\"modelyear\", \"cylinders\")\n",
    "    .agg(\n",
    "        avg(\"horsepower\").alias(\"avg_horsepower\"),\n",
    "        count(\"modelyear\").alias(\"count\"),\n",
    "    )\n",
    "    .orderBy(desc(\"modelyear\"), desc(\"cylinders\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069667c",
   "metadata": {},
   "source": [
    "**Aggregate and cube**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f3a34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+-----+\n",
      "|modelyear|cylinders|    avg_horsepower|count|\n",
      "+---------+---------+------------------+-----+\n",
      "|       82|        6|102.33333333333333|    3|\n",
      "|       82|        4| 79.14814814814815|   28|\n",
      "|       82|     null| 81.46666666666667|   31|\n",
      "|       81|        8|             105.0|    1|\n",
      "|       81|        6|100.71428571428571|    7|\n",
      "|       81|        4|             72.95|   21|\n",
      "|       81|     null| 81.03571428571429|   29|\n",
      "|       80|        6|             111.0|    2|\n",
      "|       80|        5|              67.0|    1|\n",
      "|       80|        4| 74.04347826086956|   25|\n",
      "|       80|        3|             100.0|    1|\n",
      "|       80|     null| 77.48148148148148|   29|\n",
      "|     null|        8|             105.0|    1|\n",
      "|     null|        6|102.83333333333333|   12|\n",
      "|     null|        5|              67.0|    1|\n",
      "|     null|        4|              75.7|   74|\n",
      "|     null|        3|             100.0|    1|\n",
      "|     null|     null| 80.05882352941177|   89|\n",
      "+---------+---------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col, count, desc\n",
    "\n",
    "subset = auto_df.filter(col(\"modelyear\") > 79)\n",
    "df = (\n",
    "    subset.cube(\"modelyear\", \"cylinders\")\n",
    "    .agg(\n",
    "        avg(\"horsepower\").alias(\"avg_horsepower\"),\n",
    "        count(\"modelyear\").alias(\"count\"),\n",
    "    )\n",
    "    .orderBy(desc(\"modelyear\"), desc(\"cylinders\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3dc24",
   "metadata": {},
   "source": [
    "## Joining and stacking DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5227da",
   "metadata": {},
   "source": [
    "**Join two DataFrames by column name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e2b76f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+---------+------------+----------+------+------------+---------+------+--------------------+-------+\n",
      "|manufacturer| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|country|\n",
      "+------------+----+---------+------------+----------+------+------------+---------+------+--------------------+-------+\n",
      "|   chevrolet|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|     us|\n",
      "|       buick|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|     us|\n",
      "|    plymouth|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|     us|\n",
      "|         amc|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|     us|\n",
      "|        ford|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|     us|\n",
      "|        ford|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|     us|\n",
      "|   chevrolet|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|     us|\n",
      "|    plymouth|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|     us|\n",
      "|     pontiac|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|     us|\n",
      "|         amc|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|     us|\n",
      "|       dodge|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|     us|\n",
      "|    plymouth|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|     us|\n",
      "|   chevrolet|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|     us|\n",
      "|       buick|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|     us|\n",
      "|      toyota|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|  japan|\n",
      "|    plymouth|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|     us|\n",
      "|         amc|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|     us|\n",
      "|        ford|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|     us|\n",
      "|      datsun|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|  japan|\n",
      "|  volkswagen|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|germany|\n",
      "+------------+----+---------+------------+----------+------+------------+---------+------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Load a list of manufacturer / country pairs.\n",
    "countries = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/manufacturers.csv\")\n",
    ")\n",
    "\n",
    "# Add a manufacturers column, to join with the manufacturers list.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df.withColumn(\"manufacturer\", first_word_udf(auto_df.carname))\n",
    "\n",
    "# The actual join.\n",
    "df = df.join(countries, \"manufacturer\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d742bb",
   "metadata": {},
   "source": [
    "**Join two DataFrames with an expression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6297633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|manufacturer|manufacturer|country|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|   chevrolet|   chevrolet|     us|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|       buick|       buick|     us|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|    plymouth|    plymouth|     us|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|         amc|         amc|     us|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|        ford|        ford|     us|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|        ford|        ford|     us|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|   chevrolet|   chevrolet|     us|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|    plymouth|    plymouth|     us|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|     pontiac|     pontiac|     us|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|         amc|         amc|     us|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|       dodge|       dodge|     us|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|    plymouth|    plymouth|     us|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|   chevrolet|   chevrolet|     us|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|       buick|       buick|     us|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|      toyota|      toyota|  japan|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|    plymouth|    plymouth|     us|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|         amc|         amc|     us|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|        ford|        ford|     us|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|      datsun|      datsun|  japan|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|  volkswagen|  volkswagen|germany|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Load a list of manufacturer / country pairs.\n",
    "countries = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/manufacturers.csv\")\n",
    ")\n",
    "\n",
    "# Add a manufacturers column, to join with the manufacturers list.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df.withColumn(\"manufacturer\", first_word_udf(auto_df.carname))\n",
    "\n",
    "# The actual join.\n",
    "df = df.join(countries, df.manufacturer == countries.manufacturer)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a29a54",
   "metadata": {},
   "source": [
    "**Multiple join conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d253c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|manufacturer|manufacturer|country|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|   chevrolet|   chevrolet|     us|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|       buick|       buick|     us|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|    plymouth|    plymouth|     us|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|         amc|         amc|     us|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|        ford|        ford|     us|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|        ford|        ford|     us|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|   chevrolet|   chevrolet|     us|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|    plymouth|    plymouth|     us|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|     pontiac|     pontiac|     us|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|         amc|         amc|     us|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|       dodge|       dodge|     us|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|    plymouth|    plymouth|     us|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|   chevrolet|   chevrolet|     us|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|       buick|       buick|     us|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|      toyota|      toyota|  japan|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|    plymouth|    plymouth|     us|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|         amc|         amc|     us|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|        ford|        ford|     us|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|      datsun|      datsun|  japan|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|  volkswagen|  volkswagen|germany|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Load a list of manufacturer / country pairs.\n",
    "countries = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/manufacturers.csv\")\n",
    ")\n",
    "\n",
    "# Add a manufacturers column, to join with the manufacturers list.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df.withColumn(\"manufacturer\", first_word_udf(auto_df.carname))\n",
    "\n",
    "# The actual join.\n",
    "df = df.join(\n",
    "    countries,\n",
    "    (df.manufacturer == countries.manufacturer)\n",
    "    | (df.mpg == countries.manufacturer),\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df10814",
   "metadata": {},
   "source": [
    "**Various Spark join types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "438052a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner join on one column.\n",
    "joined = auto_df.join(auto_df, \"carname\")\n",
    "\n",
    "# Left (outer) join.\n",
    "joined = auto_df.join(auto_df, \"carname\", \"left\")\n",
    "\n",
    "# Left anti (not in) join.\n",
    "joined = auto_df.join(auto_df, \"carname\", \"left_anti\")\n",
    "\n",
    "# Right (outer) join.\n",
    "joined = auto_df.join(auto_df, \"carname\", \"right\")\n",
    "\n",
    "# Full join.\n",
    "joined = auto_df.join(auto_df, \"carname\", \"full\")\n",
    "\n",
    "# Cross join.\n",
    "df = auto_df.crossJoin(auto_df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e2e14",
   "metadata": {},
   "source": [
    "**Concatenate two DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ccad3cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.format(\"csv\").option(\"header\", True).load(\"data/part1.csv\")\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", True).load(\"data/part2.csv\")\n",
    "df = df1.union(df2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf165786",
   "metadata": {},
   "source": [
    "**Load multiple files into a single DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63196078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|20.0|        6|       225.0|     100.0| 3651.|        17.7|       76|     1|      dodge aspen se|\n",
      "|18.0|        6|       250.0|     78.00| 3574.|        21.0|       76|     1|   ford granada ghia|\n",
      "|18.5|        6|       250.0|     110.0| 3645.|        16.2|       76|     1|  pontiac ventura sj|\n",
      "|17.5|        6|       258.0|     95.00| 3193.|        17.8|       76|     1|       amc pacer d/l|\n",
      "|29.5|        4|       97.00|     71.00| 1825.|        12.2|       76|     2|   volkswagen rabbit|\n",
      "|32.0|        4|       85.00|     70.00| 1990.|        17.0|       76|     3|        datsun b-210|\n",
      "|28.0|        4|       97.00|     75.00| 2155.|        16.4|       76|     3|      toyota corolla|\n",
      "|26.5|        4|       140.0|     72.00| 2565.|        13.6|       76|     1|          ford pinto|\n",
      "|20.0|        4|       130.0|     102.0| 3150.|        15.7|       76|     2|           volvo 245|\n",
      "|13.0|        8|       318.0|     150.0| 3940.|        13.2|       76|     1|plymouth volare p...|\n",
      "|19.0|        4|       120.0|     88.00| 3270.|        21.9|       76|     2|         peugeot 504|\n",
      "|19.0|        6|       156.0|     108.0| 2930.|        15.5|       76|     3|      toyota mark ii|\n",
      "|16.5|        6|       168.0|     120.0| 3820.|        16.7|       76|     2|  mercedes-benz 280s|\n",
      "|16.5|        8|       350.0|     180.0| 4380.|        12.1|       76|     1|    cadillac seville|\n",
      "|13.0|        8|       350.0|     145.0| 4055.|        12.0|       76|     1|           chevy c10|\n",
      "|13.0|        8|       302.0|     130.0| 3870.|        15.0|       76|     1|           ford f108|\n",
      "|13.0|        8|       318.0|     150.0| 3755.|        14.0|       76|     1|          dodge d100|\n",
      "|31.5|        4|       98.00|     68.00| 2045.|        18.5|       77|     3|   honda accord cvcc|\n",
      "|30.0|        4|       111.0|     80.00| 2155.|        14.8|       77|     1|buick opel isuzu ...|\n",
      "|36.0|        4|       79.00|     58.00| 1825.|        18.6|       77|     2|       renault 5 gtl|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Approach 1: Use a list.\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load([\"data/part1.csv\", \"data/part2.csv\"])\n",
    ")\n",
    "\n",
    "# Approach 2: Use a wildcard.\n",
    "df = spark.read.format(\"csv\").option(\"header\", True).load(\"data/part*.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f91df0",
   "metadata": {},
   "source": [
    "**Subtract DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3249f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|33.5|        4|       85.00|     70.00| 1945.|        16.8|       77|     3|datsun f-10 hatch...|\n",
      "|37.0|        4|       91.00|     68.00| 2025.|        18.2|       82|     3|  mazda glc custom l|\n",
      "|26.0|        4|       116.0|     75.00| 2246.|        14.0|       74|     2|         fiat 124 tc|\n",
      "|31.0|        4|       112.0|     85.00| 2575.|        16.2|       82|     1|pontiac j2000 se ...|\n",
      "|29.0|        4|       90.00|     70.00| 1937.|        14.0|       75|     2|   volkswagen rabbit|\n",
      "|37.2|        4|       86.00|     65.00| 2019.|        16.4|       80|     3|          datsun 310|\n",
      "|26.0|        4|       98.00|     90.00| 2265.|        15.5|       73|     2|fiat 124 sport coupe|\n",
      "|40.9|        4|       85.00|      null| 1835.|        17.3|       80|     2|renault lecar deluxe|\n",
      "|35.1|        4|       81.00|     60.00| 1760.|        16.1|       81|     3|    honda civic 1300|\n",
      "|32.8|        4|       78.00|     52.00| 1985.|        19.4|       78|     3|    mazda glc deluxe|\n",
      "|34.1|        4|       86.00|     65.00| 1975.|        15.2|       79|     3|    maxda glc deluxe|\n",
      "|25.0|        4|       104.0|     95.00| 2375.|        17.5|       70|     2|            saab 99e|\n",
      "|26.0|        4|       97.00|     78.00| 2300.|        14.5|       74|     2|          opel manta|\n",
      "|27.0|        4|       101.0|     83.00| 2202.|        15.3|       76|     2|        renault 12tl|\n",
      "|29.5|        4|       97.00|     71.00| 1825.|        12.2|       76|     2|   volkswagen rabbit|\n",
      "|46.6|        4|       86.00|     65.00| 2110.|        17.9|       80|     3|           mazda glc|\n",
      "|34.0|        4|       112.0|     88.00| 2395.|        18.0|       82|     1|chevrolet cavalie...|\n",
      "|36.1|        4|       91.00|     60.00| 1800.|        16.4|       78|     3|    honda civic cvcc|\n",
      "|38.1|        4|       89.00|     60.00| 1968.|        18.8|       80|     3|toyota corolla te...|\n",
      "|31.0|        4|       71.00|     65.00| 1773.|        19.0|       71|     3| toyota corolla 1200|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.subtract(auto_df.where(col(\"mpg\") < \"25\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f1db5",
   "metadata": {},
   "source": [
    "## Loading File Metadata and Processing Files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d420a",
   "metadata": {},
   "source": [
    "**Load Local File Details into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f4d84b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|file|path|size|mtime|\n",
      "+----+----+----+-----+\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructField,\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    ")\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Simple: Use glob and only file names.\n",
    "files = [[x] for x in glob.glob(\"/etc/*\")]\n",
    "#df = spark.createDataFrame(files)\n",
    "\n",
    "# Advanced: Use os.walk and extended attributes.\n",
    "target_path = \"/etc\"\n",
    "entries = []\n",
    "walker = os.walk(target_path)\n",
    "for root, dirs, files in walker:\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        try:\n",
    "            stat_info = os.stat(full_path)\n",
    "            entries.append(\n",
    "                [\n",
    "                    file,\n",
    "                    full_path,\n",
    "                    stat_info.st_size,\n",
    "                    datetime.datetime.fromtimestamp(stat_info.st_mtime),\n",
    "                ]\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"file\", StringType(), False),\n",
    "        StructField(\"path\", StringType(), False),\n",
    "        StructField(\"size\", LongType(), False),\n",
    "        StructField(\"mtime\", TimestampType(), False),\n",
    "    ]\n",
    ")\n",
    "df = spark.createDataFrame(entries, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f13db",
   "metadata": {},
   "source": [
    "**Load Files from Oracle Cloud Infrastructure into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f04e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructField,\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    ")\n",
    "\n",
    "# Requires an object_store_client object.\n",
    "# See https://oracle-cloud-infrastructure-python-sdk.readthedocs.io/en/latest/api/object_storage/client/oci.object_storage.ObjectStorageClient.html\n",
    "input_bucket = \"oow_2019_dataflow_lab\"\n",
    "raw_inputs = object_store_client.list_objects(\n",
    "    object_store_client.get_namespace().data,\n",
    "    input_bucket,\n",
    "    fields=\"size,md5,timeModified\",\n",
    ")\n",
    "files = [\n",
    "    [x.name, x.size, x.time_modified, x.md5] for x in raw_inputs.data.objects\n",
    "]\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"name\", StringType(), False),\n",
    "        StructField(\"size\", LongType(), True),\n",
    "        StructField(\"modified\", TimestampType(), True),\n",
    "        StructField(\"md5\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "df = spark.createDataFrame(files, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a76d5",
   "metadata": {},
   "source": [
    "**Transform Many Images using Pillow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "50151915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['data\\\\resize_image1.png'], ['data\\\\resize_image2.png'], ['data\\\\resize_image3.png'], ['data\\\\resize_image4.png']]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def resize_an_image(row):\n",
    "    width, height = 128, 128\n",
    "    file_name = row._1\n",
    "    new_name = file_name.replace(\".png\", \".resized.png\")\n",
    "    img = Image.open(file_name)\n",
    "    img = img.resize((width, height), Image.ANTIALIAS)\n",
    "    img.save(new_name)\n",
    "\n",
    "files = [[x] for x in glob.glob(\"data/resize_image?.png\")]\n",
    "print(files)\n",
    "df = spark.createDataFrame(files)\n",
    "df.foreach(resize_an_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f43a3",
   "metadata": {},
   "source": [
    "## Dealing with NULLs and NaNs in DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e841ebc",
   "metadata": {},
   "source": [
    "**Filter rows with None or Null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "21786e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.where(col(\"horsepower\").isNull())\n",
    "df = auto_df.where(col(\"horsepower\").isNotNull())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f1771",
   "metadata": {},
   "source": [
    "**Drop rows with Null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2901615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "|mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|carname|\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# thresh controls the number of nulls before the row gets dropped.\n",
    "# subset controls the columns to consider.\n",
    "df = auto_df.na.drop(thresh=2, subset=(\"horsepower\",))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3926ae",
   "metadata": {},
   "source": [
    "**Count all Null or NaN values in a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b05191eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "|mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|carname|\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "|  0|        0|           0|         6|     0|           0|        0|     0|      0|\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "\n",
    "df = auto_df.select(\n",
    "    [count(when(isnan(c), c)).alias(c) for c in auto_df.columns]\n",
    ")\n",
    "df = auto_df.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in auto_df.columns]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd9952",
   "metadata": {},
   "source": [
    "## Parsing and processing dates and times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf68c27",
   "metadata": {},
   "source": [
    "**Convert an ISO 8601 formatted date string to date type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "862a7968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  date_col|\n",
      "+----------+\n",
      "|2021-01-01|\n",
      "|2022-01-01|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.sparkContext.parallelize([[\"2021-01-01\"], [\"2022-01-01\"]]).toDF(\n",
    "    [\"date_col\"]\n",
    ")\n",
    "df = df.withColumn(\"date_col\", col(\"date_col\").cast(\"date\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ead7e6",
   "metadata": {},
   "source": [
    "**Convert a custom formatted date string to date type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61448b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  date_col|\n",
      "+----------+\n",
      "|2021-01-01|\n",
      "|2022-01-01|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "df = spark.sparkContext.parallelize([[\"20210101\"], [\"20220101\"]]).toDF(\n",
    "    [\"date_col\"]\n",
    ")\n",
    "df = df.withColumn(\"date_col\", to_date(col(\"date_col\"), \"yyyyddMM\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd88cc2",
   "metadata": {},
   "source": [
    "**Get the last day of the current month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "94ae2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  date_col|  last_day|\n",
      "+----------+----------+\n",
      "|2020-01-01|2020-01-31|\n",
      "|1712-02-10|1712-02-29|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, last_day\n",
    "\n",
    "df = spark.sparkContext.parallelize([[\"2020-01-01\"], [\"1712-02-10\"]]).toDF(\n",
    "    [\"date_col\"]\n",
    ")\n",
    "df = df.withColumn(\"date_col\", col(\"date_col\").cast(\"date\")).withColumn(\n",
    "    \"last_day\", last_day(col(\"date_col\"))\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a47fc",
   "metadata": {},
   "source": [
    "**Convert UNIX (seconds since epoch) timestamp to date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ab41952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|    ts_col|           date_col|\n",
      "+----------+-------------------+\n",
      "|1590183026|2020-05-23 03:00:26|\n",
      "|2000000000|2033-05-18 09:03:20|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "df = spark.sparkContext.parallelize([[\"1590183026\"], [\"2000000000\"]]).toDF(\n",
    "    [\"ts_col\"]\n",
    ")\n",
    "df = df.withColumn(\"date_col\", from_unixtime(col(\"ts_col\")))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ee1bf",
   "metadata": {},
   "source": [
    "**Load a CSV file with complex dates into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b0058ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                date|             parsed|\n",
      "+--------------------+-------------------+\n",
      "| 2012-01-01 11:12:13|2012-01-01 11:12:13|\n",
      "|2012-01-01 11:12:...|2012-01-01 09:42:13|\n",
      "|2012-01-01 11:12:...|2012-01-01 11:12:13|\n",
      "|    2012-01-01 11:12|2012-01-01 11:12:00|\n",
      "|2012-01-01 11:12 ...|2012-01-01 11:12:00|\n",
      "| 2012-01-01 11:12 PM|2012-01-01 23:12:00|\n",
      "| 01-01-2012 11:12:13|2012-01-01 11:12:13|\n",
      "|01-01-2012 11:12:...|2012-01-01 09:42:13|\n",
      "|01-01-2012 11:12:...|2012-01-01 11:12:13|\n",
      "|    01-01-2012 11:12|2012-01-01 11:12:00|\n",
      "|01-01-2012 11:12 ...|2012-01-01 11:12:00|\n",
      "| 01-01-2012 11:12 PM|2012-01-01 23:12:00|\n",
      "|   01/01/12 11:12:13|2012-01-01 11:12:13|\n",
      "|01/01/12 11:12:13...|2012-01-01 09:42:13|\n",
      "|01/01/12 11:12:13 AM|2012-01-01 11:12:13|\n",
      "|      01/01/12 11:12|2012-01-01 11:12:00|\n",
      "|01/01/12 11:12 +0530|2012-01-01 11:12:00|\n",
      "|   01/01/12 11:12 PM|2012-01-01 23:12:00|\n",
      "|     1/1/12 11:12:13|2012-01-01 11:12:13|\n",
      "|1/1/12 11:12:13 +...|2012-01-01 09:42:13|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import TimestampType\n",
    "import dateparser\n",
    "\n",
    "# Use the dateparser module to convert many formats into timestamps.\n",
    "date_convert = udf(\n",
    "    lambda x: dateparser.parse(x) if x is not None else None, TimestampType()\n",
    ")\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/date_examples.csv\")\n",
    ")\n",
    "df = df.withColumn(\"parsed\", date_convert(df.date))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b582e1",
   "metadata": {},
   "source": [
    "## Analyzing unstructured data like JSON, XML, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef3838",
   "metadata": {},
   "source": [
    "**Flatten top level text fields in a JSONl document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b26da54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "|symbol|            longName|  marketCap|previousClose|fiftyTwoWeekHigh|fiftyTwoWeekLow|trailingPE|\n",
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "|  ACLS|Axcelis Technolog...|  747277888|        22.58|            31.5|          12.99| 21.616652|\n",
      "|  AMSC|American Supercon...|  403171712|        14.69|            18.5|            4.4|      null|\n",
      "|   ATH| Athene Holding Ltd.| 6210204672|        33.31|           50.43|          13.37| 13.404612|\n",
      "|  BLDR|Builders FirstSou...| 3659266048|        31.69|           34.69|            9.0| 17.721876|\n",
      "|   BRC|   Brady Corporation| 2069810944|        41.27|           59.11|           33.0| 18.997612|\n",
      "|  CATC|   Cambridge Bancorp|  437452224|        64.43|            82.0|           44.2| 14.195144|\n",
      "|  CBSH|Commerce Bancshar...| 6501258752|        58.54|           71.92|          45.51|  22.01284|\n",
      "|  CFFI|C&F Financial Cor...|  113067632|        29.18|           57.61|           28.0|  6.614728|\n",
      "|  CFFN|Capitol Federal F...| 1613282304|        11.28|           14.57|           8.75| 22.937624|\n",
      "|  COHR|      Coherent, Inc.| 2668193024|       112.97|          178.08|          78.21|      null|\n",
      "|    DD|DuPont de Nemours...|43420598272|        59.28|           73.49|          28.33|      null|\n",
      "|   ELA|  Envela Corporation|  116851904|         4.27|             6.2|           1.25|      null|\n",
      "|  EPZM|       Epizyme, Inc.| 1119302272|        11.51|           27.82|           9.74|      null|\n",
      "|  EQBK|Equity Bancshares...|  277166304|         19.0|           31.91|          12.49|      null|\n",
      "|   ETR| Entergy Corporation|21534695424|       109.01|          135.55|          75.19| 17.555084|\n",
      "|   FBP|      First BanCorp.| 1363487488|         6.51|           11.01|            3.5|13.0753145|\n",
      "|  FNCB|  FNCB Bancorp, Inc.|  111698856|          5.4|            8.86|           5.08|  9.355932|\n",
      "|  HBCP|  Home Bancorp, Inc.|  232667520|        26.08|            40.0|          18.57| 12.977022|\n",
      "|  HWKN|       Hawkins, Inc.|  541985152|        50.01|           59.89|          26.82| 17.837837|\n",
      "|   JBT|John Bean Technol...| 2835567104|         91.0|          119.78|          56.17| 20.934645|\n",
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Load JSONl into a DataFrame. Schema is inferred automatically.\n",
    "base = spark.read.json(\"data/financial.jsonl\")\n",
    "\n",
    "# Extract interesting fields. Alias keeps columns readable.\n",
    "target_json_fields = [\n",
    "    col(\"symbol\").alias(\"symbol\"),\n",
    "    col(\"quoteType.longName\").alias(\"longName\"),\n",
    "    col(\"price.marketCap.raw\").alias(\"marketCap\"),\n",
    "    col(\"summaryDetail.previousClose.raw\").alias(\"previousClose\"),\n",
    "    col(\"summaryDetail.fiftyTwoWeekHigh.raw\").alias(\"fiftyTwoWeekHigh\"),\n",
    "    col(\"summaryDetail.fiftyTwoWeekLow.raw\").alias(\"fiftyTwoWeekLow\"),\n",
    "    col(\"summaryDetail.trailingPE.raw\").alias(\"trailingPE\"),\n",
    "]\n",
    "df = base.select(target_json_fields)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec48388",
   "metadata": {},
   "source": [
    "**Flatten top level text fields from a JSON column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4ac4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "|symbol|            longName|  marketCap|previousClose|fiftyTwoWeekHigh|fiftyTwoWeekLow|trailingPE|\n",
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "|  ACLS|Axcelis Technolog...|  747277888|        22.58|            31.5|          12.99| 21.616652|\n",
      "|  AMSC|American Supercon...|  403171712|        14.69|            18.5|            4.4|      null|\n",
      "|   ATH| Athene Holding Ltd.| 6210204672|        33.31|           50.43|          13.37| 13.404612|\n",
      "|  BLDR|Builders FirstSou...| 3659266048|         null|            null|           null|      null|\n",
      "|   BRC|   Brady Corporation| 2069810944|         null|            null|           null|      null|\n",
      "|  CATC|   Cambridge Bancorp|  437452224|         null|            null|           null|      null|\n",
      "|  CBSH|Commerce Bancshar...| 6501258752|         null|            null|           null|      null|\n",
      "|  CFFI|C&F Financial Cor...|  113067632|         null|            null|           null|      null|\n",
      "|  CFFN|Capitol Federal F...| 1613282304|         null|            null|           null|      null|\n",
      "|  COHR|      Coherent, Inc.| 2668193024|       112.97|          178.08|          78.21|      null|\n",
      "|    DD|DuPont de Nemours...|       null|         null|            null|           null|      null|\n",
      "|   ELA|  Envela Corporation|  116851904|         null|            null|           null|      null|\n",
      "|  EPZM|       Epizyme, Inc.| 1119302272|         null|            null|           null|      null|\n",
      "|  EQBK|Equity Bancshares...|  277166304|         null|            null|           null|      null|\n",
      "|   ETR| Entergy Corporation|21534695424|         null|            null|           null|      null|\n",
      "|   FBP|      First BanCorp.| 1363487488|         null|            null|           null|      null|\n",
      "|  FNCB|  FNCB Bancorp, Inc.|  111698856|         null|            null|           null|      null|\n",
      "|  HBCP|  Home Bancorp, Inc.|  232667520|         null|            null|           null|      null|\n",
      "|  HWKN|       Hawkins, Inc.|  541985152|         null|            null|           null|      null|\n",
      "|   JBT|John Bean Technol...| 2835567104|         null|            null|           null|      null|\n",
      "+------+--------------------+-----------+-------------+----------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, from_json, schema_of_json\n",
    "\n",
    "# quote/escape options needed when loading CSV containing JSON.\n",
    "base = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"quote\", '\"')\n",
    "    .option(\"escape\", '\"')\n",
    "    .load(\"data/financial.csv\")\n",
    ")\n",
    "\n",
    "# Infer JSON schema from one entry in the DataFrame.\n",
    "sample_json_document = base.select(\"financial_data\").first()[0]\n",
    "schema = schema_of_json(sample_json_document)\n",
    "\n",
    "# Parse using this schema.\n",
    "parsed = base.withColumn(\"parsed\", from_json(\"financial_data\", schema))\n",
    "\n",
    "# Extract interesting fields.\n",
    "target_json_fields = [\n",
    "    col(\"parsed.symbol\").alias(\"symbol\"),\n",
    "    col(\"parsed.quoteType.longName\").alias(\"longName\"),\n",
    "    col(\"parsed.price.marketCap.raw\").alias(\"marketCap\"),\n",
    "    col(\"parsed.summaryDetail.previousClose.raw\").alias(\"previousClose\"),\n",
    "    col(\"parsed.summaryDetail.fiftyTwoWeekHigh.raw\").alias(\"fiftyTwoWeekHigh\"),\n",
    "    col(\"parsed.summaryDetail.fiftyTwoWeekLow.raw\").alias(\"fiftyTwoWeekLow\"),\n",
    "    col(\"parsed.summaryDetail.trailingPE.raw\").alias(\"trailingPE\"),\n",
    "]\n",
    "df = parsed.select(target_json_fields)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8e18c",
   "metadata": {},
   "source": [
    "**Unnest an array of complex structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "481cad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+------------+------------+\n",
      "|symbol|   endDate|      cash| totalAssets|   totalLiab|\n",
      "+------+----------+----------+------------+------------+\n",
      "|  ACLS|2020-06-30| 190340000|   588564000|   143540000|\n",
      "|  ACLS|2020-03-31| 174745000|   562573000|   135401000|\n",
      "|  ACLS|2019-12-31| 139881000|   548094000|   128667000|\n",
      "|  ACLS|2019-09-30| 155317000|   530477000|   122630000|\n",
      "|  AMSC|2020-06-30|  20709000|   109670000|    40251000|\n",
      "|  AMSC|2020-03-31|  24699000|   124109000|    51890000|\n",
      "|  AMSC|2019-12-31|  25481000|   123491000|    46303000|\n",
      "|  AMSC|2019-09-30|  52829000|   117443000|    40757000|\n",
      "|   ATH|2020-06-30|6240000000|183241000000|167602000000|\n",
      "|   ATH|2020-03-31|5419000000|142179000000|131649000000|\n",
      "|   ATH|2019-12-31|4240000000|146875000000|132734000000|\n",
      "|   ATH|2019-09-30|3836000000|144202000000|130657000000|\n",
      "|  BLDR|2020-06-30| 385461000|  3764678000|  2848744000|\n",
      "|  BLDR|2020-03-31| 163872000|  3561358000|  2727820000|\n",
      "|  BLDR|2019-12-31|  14096000|  3249490000|  2424537000|\n",
      "|  BLDR|2019-09-30|  43271000|  3297759000|  2518758000|\n",
      "|   BRC|2020-07-31| 217643000|  1142466000|   279394000|\n",
      "|   BRC|2020-04-30| 238880000|  1140342000|   319740000|\n",
      "|   BRC|2020-01-31| 289803000|  1215798000|   315874000|\n",
      "|   BRC|2019-10-31| 295093000|  1231222000|   354687000|\n",
      "+------+----------+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "base = spark.read.json(\"data/financial.jsonl\")\n",
    "\n",
    "# Analyze balance sheet data, which is held in an array of complex types.\n",
    "target_json_fields = [\n",
    "    col(\"symbol\").alias(\"symbol\"),\n",
    "    col(\"balanceSheetHistoryQuarterly.balanceSheetStatements\").alias(\n",
    "        \"balanceSheetStatements\"\n",
    "    ),\n",
    "]\n",
    "selected = base.select(target_json_fields)\n",
    "\n",
    "# Select a few fields from the balance sheet statement data.\n",
    "target_json_fields = [\n",
    "    col(\"symbol\").alias(\"symbol\"),\n",
    "    col(\"col.endDate.fmt\").alias(\"endDate\"),\n",
    "    col(\"col.cash.raw\").alias(\"cash\"),\n",
    "    col(\"col.totalAssets.raw\").alias(\"totalAssets\"),\n",
    "    col(\"col.totalLiab.raw\").alias(\"totalLiab\"),\n",
    "]\n",
    "\n",
    "# Balance sheet data is in an array, use explode to generate one row per entry.\n",
    "df = selected.select(\"symbol\", explode(\"balanceSheetStatements\")).select(\n",
    "    target_json_fields\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe45748",
   "metadata": {},
   "source": [
    "## Using Python's Pandas library to augment Spark. Some operations require the pyarrow library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d7ced",
   "metadata": {},
   "source": [
    "**Convert Spark DataFrame to Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b08b8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = auto_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe54d74",
   "metadata": {},
   "source": [
    "**Convert Pandas DataFrame to Spark DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "37af2c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code converts everything to strings.\n",
    "# If you want to preserve types, see https://gist.github.com/tonyfraser/79a255aa8a9d765bd5cf8bd13597171e\n",
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "\n",
    "schema = StructType(\n",
    "    [StructField(name, StringType(), True) for name in pandas_df.columns]\n",
    ")\n",
    "df = spark.createDataFrame(pandas_df, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6fca0c",
   "metadata": {},
   "source": [
    "**Convert N rows from a DataFrame to a Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f056cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "pdf = auto_df.limit(N).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c24a8",
   "metadata": {},
   "source": [
    "**Grouped Aggregation with Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aca3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pandas import DataFrame\n",
    "\n",
    "@pandas_udf(\"double\")\n",
    "def mean_udaf(pdf: DataFrame) -> float:\n",
    "    return pdf.mean()\n",
    "\n",
    "df = auto_df.groupby(\"cylinders\").agg(mean_udaf(auto_df.mpg))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089b0c2",
   "metadata": {},
   "source": [
    "**Use a Pandas Grouped Map Function via applyInPandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(pdf):\n",
    "    minv = pdf.horsepower.min()\n",
    "    maxv = pdf.horsepower.max() - minv\n",
    "    return pdf.assign(horsepower=(pdf.horsepower - minv) / maxv * 100)\n",
    "\n",
    "df = auto_df.groupby(\"cylinders\").applyInPandas(rescale, auto_df.schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc24c4",
   "metadata": {},
   "source": [
    "## Extracting key statistics out of a body of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25fb97",
   "metadata": {},
   "source": [
    "**Compute the number of NULLs across all columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e4c33cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "|mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|carname|\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "|  0|        0|           0|         6|     0|           0|        0|     0|      0|\n",
      "+---+---------+------------+----------+------+------------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "df = auto_df.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in auto_df.columns]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9b7bd",
   "metadata": {},
   "source": [
    "**Compute average values of all numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "53b1fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|      avg(weight)| avg(acceleration)|   avg(cylinders)|          avg(mpg)|   avg(horsepower)| avg(displacement)|\n",
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|2970.424623115578|15.568090452261291|5.454773869346734|23.514572864321615|104.46938775510205|193.42587939698493|\n",
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerics = set([\"decimal\", \"double\", \"float\", \"integer\", \"long\", \"short\"])\n",
    "exprs = {x[0]: \"avg\" for x in auto_df_fixed.dtypes if x[1] in numerics}\n",
    "df = auto_df_fixed.agg(exprs)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c5f5c",
   "metadata": {},
   "source": [
    "**Compute minimum values of all numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "be560fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "|min(weight)|min(acceleration)|min(cylinders)|min(mpg)|min(horsepower)|min(displacement)|\n",
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "|     1613.0|              8.0|           3.0|     9.0|           46.0|             68.0|\n",
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerics = set([\"decimal\", \"double\", \"float\", \"integer\", \"long\", \"short\"])\n",
    "exprs = {x[0]: \"min\" for x in auto_df_fixed.dtypes if x[1] in numerics}\n",
    "df = auto_df_fixed.agg(exprs)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89ff9e",
   "metadata": {},
   "source": [
    "**Compute maximum values of all numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9def21d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "|max(weight)|max(acceleration)|max(cylinders)|max(mpg)|max(horsepower)|max(displacement)|\n",
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "|     5140.0|             24.8|           8.0|    46.6|          230.0|            455.0|\n",
      "+-----------+-----------------+--------------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerics = set([\"decimal\", \"double\", \"float\", \"integer\", \"long\", \"short\"])\n",
    "exprs = {x[0]: \"max\" for x in auto_df_fixed.dtypes if x[1] in numerics}\n",
    "df = auto_df_fixed.agg(exprs)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc4852",
   "metadata": {},
   "source": [
    "**Compute median values of all numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "873d4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+\n",
      "|mpg_median|cylinders_median|displacement_median|horsepower_median|weight_median|acceleration_median|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+\n",
      "|      23.0|             4.0|              148.5|             93.5|       2803.5|               15.5|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "numerics = set([\"decimal\", \"double\", \"float\", \"integer\", \"long\", \"short\"])\n",
    "aggregates = []\n",
    "for name, dtype in auto_df_fixed.dtypes:\n",
    "    if dtype not in numerics:\n",
    "        continue\n",
    "    aggregates.append(\n",
    "        F.expr(\"percentile({}, 0.5)\".format(name)).alias(\n",
    "            \"{}_median\".format(name)\n",
    "        )\n",
    "    )\n",
    "df = auto_df_fixed.agg(*aggregates)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56141823",
   "metadata": {},
   "source": [
    "**Identify Outliers in a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "410a7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+------+------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|mad|median|            zscore|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+------+------------------+\n",
      "|43.1|        4|       90.00|     48.00| 1985.|        21.5|       78|     2|volkswagen rabbit...|6.0|  23.0|2.2595750000000003|\n",
      "|41.5|        4|       98.00|     76.00| 2144.|        14.7|       80|     2|           vw rabbit|6.0|  23.0| 2.079708333333333|\n",
      "|46.6|        4|       86.00|     65.00| 2110.|        17.9|       80|     3|           mazda glc|6.0|  23.0|2.6530333333333336|\n",
      "|40.8|        4|       85.00|     65.00| 2110.|        19.2|       80|     3|          datsun 210|6.0|  23.0| 2.001016666666666|\n",
      "|44.3|        4|       90.00|     48.00| 2085.|        21.7|       80|     2|vw rabbit c (diesel)|6.0|  23.0|2.3944749999999995|\n",
      "|43.4|        4|       90.00|     48.00| 2335.|        23.7|       80|     2|  vw dasher (diesel)|6.0|  23.0|            2.2933|\n",
      "|44.6|        4|       91.00|     67.00| 1850.|        13.8|       80|     3| honda civic 1500 gl|6.0|  23.0|            2.4282|\n",
      "|40.9|        4|       85.00|      null| 1835.|        17.3|       80|     2|renault lecar deluxe|6.0|  23.0| 2.012258333333333|\n",
      "|44.0|        4|       97.00|     52.00| 2130.|        24.6|       82|     2|           vw pickup|6.0|  23.0|           2.36075|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+---+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This approach uses the Median Absolute Deviation.\n",
    "# Outliers are based on variances in a single numeric column.\n",
    "# Tune outlier sensitivity using z_score_threshold.\n",
    "from pyspark.sql.functions import col, sqrt\n",
    "\n",
    "target_column = \"mpg\"\n",
    "z_score_threshold = 2\n",
    "\n",
    "# Compute the median of the target column.\n",
    "target_df = auto_df.select(target_column)\n",
    "target_df.registerTempTable(\"target_column\")\n",
    "profiled = sqlContext.sql(\n",
    "    f\"select percentile({target_column}, 0.5) as median from target_column\"\n",
    ")\n",
    "\n",
    "# Compute deviations.\n",
    "deviations = target_df.crossJoin(profiled).withColumn(\n",
    "    \"deviation\", sqrt((target_df[target_column] - profiled[\"median\"]) ** 2)\n",
    ")\n",
    "deviations.registerTempTable(\"deviations\")\n",
    "\n",
    "# The Median Absolute Deviation\n",
    "mad = sqlContext.sql(\"select percentile(deviation, 0.5) as mad from deviations\")\n",
    "\n",
    "# Add a modified z score to the original DataFrame.\n",
    "df = (\n",
    "    auto_df.crossJoin(mad)\n",
    "    .crossJoin(profiled)\n",
    "    .withColumn(\n",
    "        \"zscore\",\n",
    "        0.6745\n",
    "        * sqrt((auto_df[target_column] - profiled[\"median\"]) ** 2)\n",
    "        / mad[\"mad\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.where(col(\"zscore\") > z_score_threshold)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab4d24",
   "metadata": {},
   "source": [
    "## Upserts, updates and deletes on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927dd3e",
   "metadata": {},
   "source": [
    "**Update records in a DataFrame using Delta Tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b33c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|CHEVROLET CHEVELL...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    CHEVROLET IMPALA|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|CHEVROLET MONTE C...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "output_path = \"delta_tests\"\n",
    "\n",
    "# Currently you have to save/reload to convert from table to DataFrame.\n",
    "auto_df.write.mode(\"overwrite\").format(\"delta\").save(output_path)\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "\n",
    "# Run a SQL update operation.\n",
    "dt.update(\n",
    "    condition=expr(\"carname like 'chevr%'\"), set={\"carname\": upper(\"carname\")}\n",
    ")\n",
    "\n",
    "# Convert back to a DataFrame.\n",
    "df = dt.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea110827",
   "metadata": {},
   "source": [
    "**Merge into a Delta table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b0ad5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|version|operation|    operationMetrics|\n",
      "+-------+---------+--------------------+\n",
      "|     17|    MERGE|{numTargetRowsCop...|\n",
      "|     16|    WRITE|{numFiles -> 1, n...|\n",
      "|     15|   UPDATE|{numRemovedFiles ...|\n",
      "|     14|    WRITE|{numFiles -> 1, n...|\n",
      "|     13|    WRITE|{numFiles -> 1, n...|\n",
      "|     12|    WRITE|{numFiles -> 1, n...|\n",
      "|     11|   UPDATE|{numRemovedFiles ...|\n",
      "|     10|    WRITE|{numFiles -> 1, n...|\n",
      "|      9|   UPDATE|{numRemovedFiles ...|\n",
      "|      8|    WRITE|{numFiles -> 1, n...|\n",
      "|      7|    WRITE|{numFiles -> 1, n...|\n",
      "|      6|   UPDATE|{numRemovedFiles ...|\n",
      "|      5|    WRITE|{numFiles -> 1, n...|\n",
      "|      4|    WRITE|{numFiles -> 1, n...|\n",
      "|      3|   UPDATE|{numRemovedFiles ...|\n",
      "|      2|    WRITE|{numFiles -> 1, n...|\n",
      "|      1|    WRITE|{numFiles -> 1, n...|\n",
      "|      0|    WRITE|{numFiles -> 1, n...|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Save the original data.\n",
    "output_path = \"delta_tests\"\n",
    "auto_df.write.mode(\"overwrite\").format(\"delta\").save(output_path)\n",
    "\n",
    "# Load data that corrects some car names.\n",
    "corrected_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/auto-mpg-fixed.csv\")\n",
    ")\n",
    "\n",
    "# Merge the corrected data in.\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "ret = (\n",
    "    dt.alias(\"original\")\n",
    "    .merge(\n",
    "        corrected_df.alias(\"corrected\"),\n",
    "        \"original.modelyear = corrected.modelyear and original.weight = corrected.weight and original.acceleration = corrected.acceleration\",\n",
    "    )\n",
    "    .whenMatchedUpdate(\n",
    "        condition=expr(\"original.carname <> corrected.carname\"),\n",
    "        set={\"carname\": col(\"corrected.carname\")},\n",
    "    )\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "# Show select table history.\n",
    "df = dt.history().select(\"version operation operationMetrics\".split())\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac448479",
   "metadata": {},
   "source": [
    "**Show Table Version History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad71531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+\n",
      "|version|           timestamp|operation|\n",
      "+-------+--------------------+---------+\n",
      "|     17|2021-10-15 13:04:...|    MERGE|\n",
      "|     16|2021-10-15 13:04:...|    WRITE|\n",
      "|     15|2021-10-15 13:04:...|   UPDATE|\n",
      "|     14|2021-10-15 13:04:...|    WRITE|\n",
      "|     13|2021-10-15 13:04:...|    WRITE|\n",
      "|     12|2021-10-15 13:04:...|    WRITE|\n",
      "|     11|2021-10-15 13:03:...|   UPDATE|\n",
      "|     10|2021-10-15 13:03:...|    WRITE|\n",
      "|      9|2021-10-15 13:02:...|   UPDATE|\n",
      "|      8|2021-10-15 13:02:...|    WRITE|\n",
      "|      7|2021-10-15 13:02:...|    WRITE|\n",
      "|      6|2021-10-15 13:01:...|   UPDATE|\n",
      "|      5|2021-10-15 13:01:...|    WRITE|\n",
      "|      4|2021-10-15 13:01:...|    WRITE|\n",
      "|      3|2021-10-15 13:00:...|   UPDATE|\n",
      "|      2|2021-10-15 13:00:...|    WRITE|\n",
      "|      1|2021-10-15 13:00:...|    WRITE|\n",
      "|      0|2021-10-15 12:57:...|    WRITE|\n",
      "+-------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load our table.\n",
    "output_path = \"delta_tests\"\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "\n",
    "# Show select table history.\n",
    "df = dt.history().select(\"version timestamp operation\".split())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e331c02",
   "metadata": {},
   "source": [
    "**Load a Delta Table by Version ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "63a213b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest version is 0\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"delta_tests\"\n",
    "\n",
    "# Get versions.\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "versions = dt.history().select(\"version timestamp\".split()).orderBy(\"version\")\n",
    "oldest_version = versions.first()[0]\n",
    "print(\"Oldest version is\", oldest_version)\n",
    "\n",
    "# Load the oldest version.\n",
    "df = spark.read.format(\"delta\").option(\"versionAsOf\", oldest_version).load(output_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b149c",
   "metadata": {},
   "source": [
    "**Load a Delta Table by Timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78d81f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest timestamp is 2021-10-15 12:57:53.410000\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"delta_tests\"\n",
    "\n",
    "# Get versions.\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "versions = dt.history().select(\"version timestamp\".split()).orderBy(\"version\")\n",
    "oldest_timestamp = versions.first()[1]\n",
    "print(\"Oldest timestamp is\", oldest_timestamp)\n",
    "\n",
    "# Load the oldest version by timestamp.\n",
    "df = spark.read.format(\"delta\").option(\"timestampAsOf\", oldest_timestamp).load(output_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8e264",
   "metadata": {},
   "source": [
    "**Compact a Delta Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b086eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|version|           timestamp|\n",
      "+-------+--------------------+\n",
      "|      0|2021-10-15 12:57:...|\n",
      "|      1|2021-10-15 13:00:...|\n",
      "|      2|2021-10-15 13:00:...|\n",
      "|      3|2021-10-15 13:00:...|\n",
      "|      4|2021-10-15 13:01:...|\n",
      "|      5|2021-10-15 13:01:...|\n",
      "|      6|2021-10-15 13:01:...|\n",
      "|      7|2021-10-15 13:02:...|\n",
      "|      8|2021-10-15 13:02:...|\n",
      "|      9|2021-10-15 13:02:...|\n",
      "|     10|2021-10-15 13:03:...|\n",
      "|     11|2021-10-15 13:03:...|\n",
      "|     12|2021-10-15 13:04:...|\n",
      "|     13|2021-10-15 13:04:...|\n",
      "|     14|2021-10-15 13:04:...|\n",
      "|     15|2021-10-15 13:04:...|\n",
      "|     16|2021-10-15 13:04:...|\n",
      "|     17|2021-10-15 13:04:...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"delta_tests\"\n",
    "\n",
    "# Load table.\n",
    "dt = DeltaTable.forPath(spark, output_path)\n",
    "\n",
    "# Clean up data older than the given window.\n",
    "retention_window_hours = 168\n",
    "dt.vacuum(retention_window_hours)\n",
    "\n",
    "# Show the new versions.\n",
    "df = dt.history().select(\"version timestamp\".split()).orderBy(\"version\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc670cf",
   "metadata": {},
   "source": [
    "## Spark Streaming (Focuses on Structured Streaming)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6abd2",
   "metadata": {},
   "source": [
    "**Add the current timestamp to a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "81af3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|           timestamp|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|2021-10-15 13:10:...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|2021-10-15 13:10:...|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|2021-10-15 13:10:...|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|2021-10-15 13:10:...|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|2021-10-15 13:10:...|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|2021-10-15 13:10:...|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|2021-10-15 13:10:...|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|2021-10-15 13:10:...|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|2021-10-15 13:10:...|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|2021-10-15 13:10:...|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|2021-10-15 13:10:...|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|2021-10-15 13:10:...|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|2021-10-15 13:10:...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|2021-10-15 13:10:...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|2021-10-15 13:10:...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|2021-10-15 13:10:...|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|2021-10-15 13:10:...|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|2021-10-15 13:10:...|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|2021-10-15 13:10:...|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|2021-10-15 13:10:...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "df = auto_df.withColumn(\"timestamp\", current_timestamp())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe785f8",
   "metadata": {},
   "source": [
    "## Techniques for dealing with time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdeecf8",
   "metadata": {},
   "source": [
    "**Zero fill missing values in a timeseries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d9167866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------------+\n",
      "|      date|customer_id|coalesce(spend_dollars, 0)|\n",
      "+----------+-----------+--------------------------+\n",
      "|2021-09-30|          7|                         0|\n",
      "|2022-11-30|          7|                     $0.72|\n",
      "|2022-02-28|          7|                     $0.35|\n",
      "|2020-04-30|          7|                     $0.12|\n",
      "|2021-08-31|          7|                     $1.65|\n",
      "|2021-04-30|          7|                         0|\n",
      "|2020-01-31|          7|                         0|\n",
      "|2021-02-28|          7|                     $0.64|\n",
      "|2022-01-31|          7|                     $0.81|\n",
      "|2020-07-31|          7|                     $2.87|\n",
      "|2022-03-31|          7|                         0|\n",
      "|2020-11-30|          7|                     $2.52|\n",
      "|2021-06-30|          7|                         0|\n",
      "|2022-10-31|          7|                     $4.01|\n",
      "|2021-05-31|          7|                         0|\n",
      "|2020-09-30|          7|                     $6.30|\n",
      "|2022-08-31|          7|                     $0.78|\n",
      "|2020-02-29|          7|                     $0.93|\n",
      "|2021-12-31|          7|                         0|\n",
      "|2020-05-31|          7|                         0|\n",
      "+----------+-----------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "# Use distinct values of customer and date from the dataset itself.\n",
    "# In general it's safer to use known reference tables for IDs and dates.\n",
    "df = spend_df.join(\n",
    "    spend_df.select(\"customer_id\")\n",
    "    .distinct()\n",
    "    .crossJoin(spend_df.select(\"date\").distinct()),\n",
    "    [\"date\", \"customer_id\"],\n",
    "    \"right\",\n",
    ").select(\"date\", \"customer_id\", coalesce(\"spend_dollars\", lit(0)))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e81e1f",
   "metadata": {},
   "source": [
    "**First Time an ID is Seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "08af5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+----------+\n",
      "|      date|customer_id|spend_dollars|first_seen|\n",
      "+----------+-----------+-------------+----------+\n",
      "|2020-12-31|         51|        $2.19|2020-12-31|\n",
      "|2021-01-31|         51|        $3.40|2020-12-31|\n",
      "|2021-03-31|         51|        $3.41|2020-12-31|\n",
      "|2021-08-31|         51|       $11.21|2020-12-31|\n",
      "|2021-09-30|         51|       $11.88|2020-12-31|\n",
      "|2022-01-31|         51|        $3.04|2020-12-31|\n",
      "|2022-02-28|         51|        $2.42|2020-12-31|\n",
      "|2022-03-31|         51|        $2.44|2020-12-31|\n",
      "|2022-04-30|         51|        $2.11|2020-12-31|\n",
      "|2022-05-31|         51|        $1.62|2020-12-31|\n",
      "|2022-06-30|         51|        $0.49|2020-12-31|\n",
      "|2022-07-31|         51|        $0.07|2020-12-31|\n",
      "|2022-08-31|         51|       $12.36|2020-12-31|\n",
      "|2022-09-30|         51|        $1.00|2020-12-31|\n",
      "|2022-10-31|         51|        $0.53|2020-12-31|\n",
      "|2022-11-30|         51|        $8.82|2020-12-31|\n",
      "|2022-12-31|         51|        $0.34|2020-12-31|\n",
      "|2020-02-29|          7|        $0.93|2020-02-29|\n",
      "|2020-03-31|          7|        $0.56|2020-02-29|\n",
      "|2020-04-30|          7|        $0.12|2020-02-29|\n",
      "+----------+-----------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window().partitionBy(\"customer_id\").orderBy(\"date\")\n",
    "df = spend_df.withColumn(\"first_seen\", first(\"date\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a681b",
   "metadata": {},
   "source": [
    "**Cumulative Sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b3be8e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+-----------+\n",
      "|      date|customer_id|spend_dollars|running_sum|\n",
      "+----------+-----------+-------------+-----------+\n",
      "|2020-12-31|         51|        $2.19|       null|\n",
      "|2021-01-31|         51|        $3.40|       null|\n",
      "|2021-03-31|         51|        $3.41|       null|\n",
      "|2021-08-31|         51|       $11.21|       null|\n",
      "|2021-09-30|         51|       $11.88|       null|\n",
      "|2022-01-31|         51|        $3.04|       null|\n",
      "|2022-02-28|         51|        $2.42|       null|\n",
      "|2022-03-31|         51|        $2.44|       null|\n",
      "|2022-04-30|         51|        $2.11|       null|\n",
      "|2022-05-31|         51|        $1.62|       null|\n",
      "|2022-06-30|         51|        $0.49|       null|\n",
      "|2022-07-31|         51|        $0.07|       null|\n",
      "|2022-08-31|         51|       $12.36|       null|\n",
      "|2022-09-30|         51|        $1.00|       null|\n",
      "|2022-10-31|         51|        $0.53|       null|\n",
      "|2022-11-30|         51|        $8.82|       null|\n",
      "|2022-12-31|         51|        $0.34|       null|\n",
      "|2020-02-29|          7|        $0.93|       null|\n",
      "|2020-03-31|          7|        $0.56|       null|\n",
      "|2020-04-30|          7|        $0.12|       null|\n",
      "+----------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = (\n",
    "    Window()\n",
    "    .partitionBy(\"customer_id\")\n",
    "    .orderBy(\"date\")\n",
    "    .rangeBetween(Window.unboundedPreceding, 0)\n",
    ")\n",
    "df = spend_df.withColumn(\"running_sum\", sum(\"spend_dollars\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cea02c",
   "metadata": {},
   "source": [
    "**Cumulative Sum in a Period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2d3d1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+-----------+\n",
      "|      date|customer_id|spend_dollars|running_sum|\n",
      "+----------+-----------+-------------+-----------+\n",
      "|2021-01-31|          5|        $0.44|       null|\n",
      "|2021-02-28|          5|        $1.72|       null|\n",
      "|2021-04-30|          5|        $0.89|       null|\n",
      "|2021-08-31|          5|        $3.29|       null|\n",
      "|2021-10-31|          5|        $1.58|       null|\n",
      "|2021-12-31|          5|        $0.70|       null|\n",
      "|2021-01-31|          9|       $18.37|       null|\n",
      "|2021-02-28|          9|        $2.73|       null|\n",
      "|2021-04-30|          9|        $0.87|       null|\n",
      "|2021-06-30|          9|       $44.23|       null|\n",
      "|2021-08-31|          9|        $6.41|       null|\n",
      "|2021-10-31|          9|       $20.52|       null|\n",
      "|2021-11-30|          9|        $1.81|       null|\n",
      "|2021-12-31|          9|        $7.49|       null|\n",
      "|2022-01-31|         97|        $0.07|       null|\n",
      "|2022-02-28|         97|        $5.16|       null|\n",
      "|2022-03-31|         97|        $0.70|       null|\n",
      "|2022-04-30|         97|        $5.57|       null|\n",
      "|2022-05-31|         97|       $28.22|       null|\n",
      "|2022-06-30|         97|        $1.26|       null|\n",
      "+----------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, year\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Add an additional partition clause for the sub-period.\n",
    "w = (\n",
    "    Window()\n",
    "    .partitionBy([\"customer_id\", year(\"date\")])\n",
    "    .orderBy(\"date\")\n",
    "    .rangeBetween(Window.unboundedPreceding, 0)\n",
    ")\n",
    "df = spend_df.withColumn(\"running_sum\", sum(\"spend_dollars\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbebcf3",
   "metadata": {},
   "source": [
    "**Cumulative Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "02437057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+-----------+\n",
      "|      date|customer_id|spend_dollars|running_avg|\n",
      "+----------+-----------+-------------+-----------+\n",
      "|2020-12-31|         51|        $2.19|       null|\n",
      "|2021-01-31|         51|        $3.40|       null|\n",
      "|2021-03-31|         51|        $3.41|       null|\n",
      "|2021-08-31|         51|       $11.21|       null|\n",
      "|2021-09-30|         51|       $11.88|       null|\n",
      "|2022-01-31|         51|        $3.04|       null|\n",
      "|2022-02-28|         51|        $2.42|       null|\n",
      "|2022-03-31|         51|        $2.44|       null|\n",
      "|2022-04-30|         51|        $2.11|       null|\n",
      "|2022-05-31|         51|        $1.62|       null|\n",
      "|2022-06-30|         51|        $0.49|       null|\n",
      "|2022-07-31|         51|        $0.07|       null|\n",
      "|2022-08-31|         51|       $12.36|       null|\n",
      "|2022-09-30|         51|        $1.00|       null|\n",
      "|2022-10-31|         51|        $0.53|       null|\n",
      "|2022-11-30|         51|        $8.82|       null|\n",
      "|2022-12-31|         51|        $0.34|       null|\n",
      "|2020-02-29|          7|        $0.93|       null|\n",
      "|2020-03-31|          7|        $0.56|       null|\n",
      "|2020-04-30|          7|        $0.12|       null|\n",
      "+----------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = (\n",
    "    Window()\n",
    "    .partitionBy(\"customer_id\")\n",
    "    .orderBy(\"date\")\n",
    "    .rangeBetween(Window.unboundedPreceding, 0)\n",
    ")\n",
    "df = spend_df.withColumn(\"running_avg\", avg(\"spend_dollars\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca91150",
   "metadata": {},
   "source": [
    "**Cumulative Average in a Period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bc74d80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+-----------+\n",
      "|      date|customer_id|spend_dollars|running_avg|\n",
      "+----------+-----------+-------------+-----------+\n",
      "|2021-01-31|          5|        $0.44|       null|\n",
      "|2021-02-28|          5|        $1.72|       null|\n",
      "|2021-04-30|          5|        $0.89|       null|\n",
      "|2021-08-31|          5|        $3.29|       null|\n",
      "|2021-10-31|          5|        $1.58|       null|\n",
      "|2021-12-31|          5|        $0.70|       null|\n",
      "|2021-01-31|          9|       $18.37|       null|\n",
      "|2021-02-28|          9|        $2.73|       null|\n",
      "|2021-04-30|          9|        $0.87|       null|\n",
      "|2021-06-30|          9|       $44.23|       null|\n",
      "|2021-08-31|          9|        $6.41|       null|\n",
      "|2021-10-31|          9|       $20.52|       null|\n",
      "|2021-11-30|          9|        $1.81|       null|\n",
      "|2021-12-31|          9|        $7.49|       null|\n",
      "|2022-01-31|         97|        $0.07|       null|\n",
      "|2022-02-28|         97|        $5.16|       null|\n",
      "|2022-03-31|         97|        $0.70|       null|\n",
      "|2022-04-30|         97|        $5.57|       null|\n",
      "|2022-05-31|         97|       $28.22|       null|\n",
      "|2022-06-30|         97|        $1.26|       null|\n",
      "+----------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, year\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Add an additional partition clause for the sub-period.\n",
    "w = (\n",
    "    Window()\n",
    "    .partitionBy([\"customer_id\", year(\"date\")])\n",
    "    .orderBy(\"date\")\n",
    "    .rangeBetween(Window.unboundedPreceding, 0)\n",
    ")\n",
    "df = spend_df.withColumn(\"running_avg\", avg(\"spend_dollars\").over(w))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59126ed4",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedec681",
   "metadata": {},
   "source": [
    "**Save a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cc012b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vectorAssembler.transform(auto_df_fixed)\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = assembled.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=50,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_model.write().overwrite().save(\"ml_models/rf_regression.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c0510",
   "metadata": {},
   "source": [
    "**Load a model and use it for predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "103014ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+-----------+\n",
      "|      date|customer_id|spend_dollars|running_avg|\n",
      "+----------+-----------+-------------+-----------+\n",
      "|2021-01-31|          5|        $0.44|       null|\n",
      "|2021-02-28|          5|        $1.72|       null|\n",
      "|2021-04-30|          5|        $0.89|       null|\n",
      "|2021-08-31|          5|        $3.29|       null|\n",
      "|2021-10-31|          5|        $1.58|       null|\n",
      "|2021-12-31|          5|        $0.70|       null|\n",
      "|2021-01-31|          9|       $18.37|       null|\n",
      "|2021-02-28|          9|        $2.73|       null|\n",
      "|2021-04-30|          9|        $0.87|       null|\n",
      "|2021-06-30|          9|       $44.23|       null|\n",
      "|2021-08-31|          9|        $6.41|       null|\n",
      "|2021-10-31|          9|       $20.52|       null|\n",
      "|2021-11-30|          9|        $1.81|       null|\n",
      "|2021-12-31|          9|        $7.49|       null|\n",
      "|2022-01-31|         97|        $0.07|       null|\n",
      "|2022-02-28|         97|        $5.16|       null|\n",
      "|2022-03-31|         97|        $0.70|       null|\n",
      "|2022-04-30|         97|        $5.57|       null|\n",
      "|2022-05-31|         97|       $28.22|       null|\n",
      "|2022-06-30|         97|        $1.26|       null|\n",
      "+----------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "\n",
    "# Model type and assembled features need to agree with the trained model.\n",
    "rf_model = RandomForestRegressionModel.load(\"ml_models/rf_regression.model\")\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vectorAssembler.transform(auto_df_fixed)\n",
    "\n",
    "predictions = rf_model.transform(assembled).select(\n",
    "    \"carname\", \"mpg\", \"prediction\"\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2125a",
   "metadata": {},
   "source": [
    "**A basic Linear Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "61449ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=4.28208848614513 r2=0.7017281872041321\n",
      "+--------------------+----+--------------------+------------------+\n",
      "|            features| mpg|             carname|        prediction|\n",
      "+--------------------+----+--------------------+------------------+\n",
      "|[3.0,70.0,97.0,23...|19.0|     mazda rx2 coupe|27.755527663266946|\n",
      "|[4.0,79.0,58.0,17...|39.1|      toyota starlet| 31.81445601064662|\n",
      "|[4.0,79.0,67.0,19...|31.0|         datsun b210|30.569601305646696|\n",
      "|[4.0,79.0,67.0,20...|31.0|           fiat x1.9| 30.38540530960867|\n",
      "|[4.0,81.0,60.0,17...|35.1|    honda civic 1300|31.666767288107515|\n",
      "|[4.0,85.0,52.0,20...|29.0|  chevrolet chevette|31.097138157963283|\n",
      "|[4.0,85.0,65.0,19...|37.0|      datsun 210 mpg|30.557687334778784|\n",
      "|[4.0,86.0,65.0,19...|34.1|    mazda glc deluxe| 30.55155169780576|\n",
      "|[4.0,86.0,65.0,20...|37.2|          datsun 310|  30.3894592212923|\n",
      "|[4.0,89.0,62.0,20...|37.7|       toyota tercel|30.432347566313524|\n",
      "|[4.0,89.0,71.0,19...|31.9|    vw rabbit custom| 30.36634723595696|\n",
      "|[4.0,90.0,70.0,19...|29.0|           vw rabbit|30.374503484429436|\n",
      "|[4.0,90.0,71.0,22...|25.0|           vw dasher| 29.26240346259731|\n",
      "|[4.0,90.0,75.0,21...|28.0|          dodge colt|29.389431916853336|\n",
      "|[4.0,91.0,67.0,19...|38.0|       datsun 310 gx|30.330197265536178|\n",
      "|[4.0,97.0,52.0,21...|44.0|           vw pickup| 30.67353812181474|\n",
      "|[4.0,97.0,67.0,19...|30.0|           subaru dl|30.330222642905635|\n",
      "|[4.0,97.0,75.0,22...|26.0|toyota corolla li...|28.830733669135697|\n",
      "|[4.0,98.0,66.0,18...|36.1|         ford fiesta| 31.06411111576793|\n",
      "|[4.0,98.0,76.0,21...|41.5|           vw rabbit|29.211853418080064|\n",
      "+--------------------+----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vectorAssembler.transform(auto_df_fixed)\n",
    "assembled = assembled.select([\"features\", \"mpg\", \"carname\"])\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = assembled.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    "    maxIter=10,\n",
    "    regParam=0.3,\n",
    "    elasticNetParam=0.8,\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Stats for training.\n",
    "print(\n",
    "    \"RMSE={} r2={}\".format(\n",
    "        lr_model.summary.rootMeanSquaredError, lr_model.summary.r2\n",
    "    )\n",
    ")\n",
    "\n",
    "# Make predictions.\n",
    "df = lr_model.transform(test_df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79402ecc",
   "metadata": {},
   "source": [
    "**A basic Random Forest Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d0909ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=4.004456659636584 r2=0.6971935994840013\n",
      "+--------------------+----+--------------------+------------------+\n",
      "|            features| mpg|             carname|        prediction|\n",
      "+--------------------+----+--------------------+------------------+\n",
      "|[3.0,70.0,90.0,21...|18.0|           mazda rx3| 30.94928554536791|\n",
      "|[3.0,70.0,100.0,2...|23.7|       mazda rx-7 gs| 25.43126493780938|\n",
      "|[4.0,68.0,49.0,18...|29.0|            fiat 128| 32.40053144415414|\n",
      "|[4.0,79.0,67.0,19...|31.0|         datsun b210|  33.7235987941858|\n",
      "|[4.0,85.0,52.0,20...|29.0|  chevrolet chevette| 33.18542715954986|\n",
      "|[4.0,85.0,70.0,19...|32.0|        datsun b-210| 32.37318849038673|\n",
      "|[4.0,85.0,70.0,20...|39.4|      datsun b210 gx| 32.46577080148648|\n",
      "|[4.0,89.0,60.0,19...|38.1|toyota corolla te...| 34.77205116355555|\n",
      "|[4.0,90.0,48.0,23...|43.4|  vw dasher (diesel)| 29.27437489767383|\n",
      "|[4.0,90.0,70.0,19...|29.0|           vw rabbit|32.338163722670785|\n",
      "|[4.0,90.0,71.0,22...|25.0|           vw dasher| 32.74552587130767|\n",
      "|[4.0,91.0,60.0,18...|36.1|    honda civic cvcc| 34.13618457412647|\n",
      "|[4.0,91.0,68.0,19...|31.0|    mazda glc custom| 33.79742415262239|\n",
      "|[4.0,91.0,68.0,19...|34.1|         mazda glc 4| 33.81683288278112|\n",
      "|[4.0,96.0,69.0,21...|26.0|     renault 12 (sw)| 32.44847386719316|\n",
      "|[4.0,97.0,46.0,18...|26.0|vw 1131 deluxe sedan|29.995014995609473|\n",
      "|[4.0,97.0,52.0,21...|44.0|           vw pickup| 29.27859558169006|\n",
      "|[4.0,97.0,60.0,18...|27.0|        vw model 111|31.805192529418697|\n",
      "|[4.0,97.0,67.0,20...|32.3|              subaru|33.304197280706056|\n",
      "|[4.0,97.0,67.0,21...|33.8|           subaru dl| 32.31070684625241|\n",
      "+--------------------+----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vectorAssembler.transform(auto_df_fixed)\n",
    "assembled = assembled.select([\"features\", \"mpg\", \"carname\"])\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = assembled.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=20,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Make predictions.\n",
    "df = rf_model.transform(test_df)\n",
    "\n",
    "# Evaluate the model.\n",
    "r2 = RegressionEvaluator(\n",
    "    labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"r2\"\n",
    ").evaluate(df)\n",
    "rmse = RegressionEvaluator(\n",
    "    labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ").evaluate(df)\n",
    "print(\"RMSE={} r2={}\".format(rmse, r2))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899a02e",
   "metadata": {},
   "source": [
    "**A basic Random Forest Classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2c364d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0848582\n",
      "+----------+----------+\n",
      "|cover_type|prediction|\n",
      "+----------+----------+\n",
      "|         3|       3.0|\n",
      "|         3|       3.0|\n",
      "|         3|       3.0|\n",
      "|         3|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         3|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         3|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         6|       3.0|\n",
      "|         3|       3.0|\n",
      "|         3|       3.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "label_column = \"cover_type\"\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=covtype_df.columns,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vectorAssembler.transform(covtype_df)\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = assembled.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestClassifier(\n",
    "    numTrees=50,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=label_column,\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=label_column, predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "df = predictions.select([label_column, \"prediction\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105a95f",
   "metadata": {},
   "source": [
    "**Encode string variables before using a VectorAssembler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "26afd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=4.049613609768184\n",
      "+--------------------+----+------------------+\n",
      "|             carname| mpg|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|       chevrolet c20|10.0|13.963236650930323|\n",
      "|    chevrolet impala|11.0|14.700121067518472|\n",
      "|   dodge monaco (sw)|12.0| 13.26410052166384|\n",
      "|     ford mustang ii|13.0|16.778577097090473|\n",
      "|chevrolet chevell...|13.0|15.693756629298832|\n",
      "|          dodge d100|13.0|16.101801234512457|\n",
      "|buick century lux...|13.0|14.183162792623659|\n",
      "|    chevrolet impala|13.0|14.142938566139435|\n",
      "|   buick century 350|13.0|13.707284922409002|\n",
      "|dodge coronet cus...|14.0|14.339135518420463|\n",
      "|            ford ltd|14.0|13.958818472848062|\n",
      "|    pontiac catalina|14.0|13.952842510366192|\n",
      "|    ford gran torino|14.5|13.898588212192305|\n",
      "|         amc matador|15.0|19.555836316096187|\n",
      "|chevrolet monte c...|15.0|14.903077873745014|\n",
      "|   chevrolet bel air|15.0|15.192660604686854|\n",
      "|   buick skylark 320|15.0|13.859305124429204|\n",
      "| dodge challenger se|15.0|14.574044962558338|\n",
      "|    ford galaxie 500|15.0| 13.18607116495078|\n",
      "|         amc matador|15.5|18.801627167573137|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Add manufacturer name we will use as a string column.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df_fixed.withColumn(\n",
    "    \"manufacturer\", first_word_udf(auto_df_fixed.carname)\n",
    ")\n",
    "\n",
    "# Strings must be indexed or we will get:\n",
    "# pyspark.sql.utils.IllegalArgumentException: Data type string of column manufacturer is not supported.\n",
    "#\n",
    "# We also encode outside of the main pipeline or else we risk getting:\n",
    "#  Caused by: org.apache.spark.SparkException: Unseen label: XXX. To handle unseen labels, set Param handleInvalid to keep.\n",
    "#\n",
    "# This is because training data is selected randomly and may not have all possible categories.\n",
    "manufacturer_encoded = StringIndexer(\n",
    "    inputCol=\"manufacturer\", outputCol=\"manufacturer_encoded\"\n",
    ")\n",
    "encoded_df = manufacturer_encoded.fit(df).transform(df)\n",
    "\n",
    "# Set up our main ML pipeline.\n",
    "columns_to_assemble = [\n",
    "    \"manufacturer_encoded\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "]\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=columns_to_assemble,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = encoded_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=20,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Run the pipeline.\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf])\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions.\n",
    "df = model.transform(test_df).select(\"carname\", \"mpg\", \"prediction\")\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rmse = RegressionEvaluator(\n",
    "    labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ").evaluate(df)\n",
    "print(\"RMSE={}\".format(rmse))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e4974",
   "metadata": {},
   "source": [
    "**Get feature importances of a trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "63423394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manufacturer_encoded contributes 15.880%\n",
      "cylinders contributes 9.528%\n",
      "displacement contributes 33.756%\n",
      "horsepower contributes 22.300%\n",
      "weight contributes 15.742%\n",
      "acceleration contributes 2.794%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Add manufacturer name we will use as a string column.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df_fixed.withColumn(\n",
    "    \"manufacturer\", first_word_udf(auto_df_fixed.carname)\n",
    ")\n",
    "manufacturer_encoded = StringIndexer(\n",
    "    inputCol=\"manufacturer\", outputCol=\"manufacturer_encoded\"\n",
    ")\n",
    "encoded_df = manufacturer_encoded.fit(df).transform(df)\n",
    "\n",
    "# Set up our main ML pipeline.\n",
    "columns_to_assemble = [\n",
    "    \"manufacturer_encoded\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "]\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=columns_to_assemble,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "\n",
    "# Random test/train split.\n",
    "train_df, test_df = encoded_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=20,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Run the pipeline.\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf])\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test_df).select(\"carname\", \"mpg\", \"prediction\")\n",
    "\n",
    "# Get feature importances.\n",
    "real_model = model.stages[1]\n",
    "for feature, importance in zip(\n",
    "    columns_to_assemble, real_model.featureImportances\n",
    "):\n",
    "    print(\"{} contributes {:0.3f}%\".format(feature, importance * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7c246",
   "metadata": {},
   "source": [
    "**Automatically encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "315b7306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+\n",
      "|count(mpg)|count(cylinders)|count(displacement)|count(horsepower)|count(weight)|count(acceleration)|count(modelyear)|count(origin)|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+\n",
      "|       129|               5|                 82|               93|          351|                 95|              13|            3|\n",
      "+----------+----------------+-------------------+-----------------+-------------+-------------------+----------------+-------------+\n",
      "\n",
      "cylinders contributes 24.306%\n",
      "displacement contributes 26.336%\n",
      "horsepower contributes 12.072%\n",
      "weight contributes 20.474%\n",
      "acceleration contributes 1.966%\n",
      "modelyear contributes 13.053%\n",
      "origin contributes 1.793%\n",
      "+----+------------------+\n",
      "| mpg|        prediction|\n",
      "+----+------------------+\n",
      "|10.0|12.657973653330195|\n",
      "|13.0|15.417067504648902|\n",
      "|13.0|15.585659205159347|\n",
      "|13.0|13.537604458531975|\n",
      "|13.0|13.673820501189125|\n",
      "|13.0|12.973887751870476|\n",
      "|14.0|14.210101756749419|\n",
      "|14.0|14.275706205050477|\n",
      "|14.0|13.452953691021976|\n",
      "|14.0|13.847199076831343|\n",
      "|14.0|13.042345544078271|\n",
      "|14.0|15.177917138728798|\n",
      "|14.5|15.221721487208073|\n",
      "|15.0| 18.12587454240421|\n",
      "|15.0|18.495482655261082|\n",
      "|15.0|15.891422186215777|\n",
      "|15.0|14.210101756749419|\n",
      "|15.0|13.794290702843218|\n",
      "|15.0|14.385447056975021|\n",
      "|15.0| 13.82166967109719|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Remove non-numeric columns.\n",
    "df = auto_df_fixed.drop(\"carname\")\n",
    "\n",
    "# Profile this DataFrame to get a good value for maxCategories.\n",
    "grouped = df.agg(*(countDistinct(c) for c in df.columns))\n",
    "grouped.show()\n",
    "\n",
    "# Assemble all columns except mpg into a vector.\n",
    "feature_columns = list(df.columns)\n",
    "feature_columns.remove(\"mpg\")\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=feature_columns,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "assembled = vector_assembler.transform(df)\n",
    "\n",
    "# From profiling the dataset, 15 is a good value for max categories.\n",
    "indexer = VectorIndexer(\n",
    "    inputCol=\"features\", outputCol=\"indexed\", maxCategories=15\n",
    ")\n",
    "indexed = indexer.fit(assembled).transform(assembled)\n",
    "\n",
    "# Build and train the model.\n",
    "train_df, test_df = indexed.randomSplit([0.7, 0.3])\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=50,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Get feature importances.\n",
    "for feature, importance in zip(feature_columns, rf_model.featureImportances):\n",
    "    print(\"{} contributes {:0.3f}%\".format(feature, importance * 100))\n",
    "\n",
    "# Make predictions.\n",
    "df = rf_model.transform(test_df).select(\"mpg\", \"prediction\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4371e16",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4c4572f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model has 30 trees.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Add manufacturer name we will use as a string column.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df_fixed.withColumn(\n",
    "    \"manufacturer\", first_word_udf(auto_df_fixed.carname)\n",
    ")\n",
    "manufacturer_encoded = StringIndexer(\n",
    "    inputCol=\"manufacturer\", outputCol=\"manufacturer_encoded\"\n",
    ")\n",
    "encoded_df = manufacturer_encoded.fit(df).transform(df)\n",
    "\n",
    "# Set up our main ML pipeline.\n",
    "columns_to_assemble = [\n",
    "    \"manufacturer_encoded\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "]\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=columns_to_assemble,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=20,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Run the pipeline.\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf])\n",
    "\n",
    "# Hyperparameter search.\n",
    "target_metric = \"rmse\"\n",
    "paramGrid = (\n",
    "    ParamGridBuilder().addGrid(rf.numTrees, list(range(20, 100, 10))).build()\n",
    ")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(\n",
    "        labelCol=\"mpg\", predictionCol=\"prediction\", metricName=target_metric\n",
    "    ),\n",
    "    numFolds=2,\n",
    "    parallelism=4,\n",
    ")\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "model = crossval.fit(encoded_df)\n",
    "real_model = model.bestModel.stages[1]\n",
    "print(\"Best model has {} trees.\".format(real_model.getNumTrees))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f5106",
   "metadata": {},
   "source": [
    "**Plot Hyperparameter tuning metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "833d64cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Add manufacturer name we will use as a string column.\n",
    "first_word_udf = udf(lambda x: x.split()[0], StringType())\n",
    "df = auto_df_fixed.withColumn(\n",
    "    \"manufacturer\", first_word_udf(auto_df_fixed.carname)\n",
    ")\n",
    "manufacturer_encoded = StringIndexer(\n",
    "    inputCol=\"manufacturer\", outputCol=\"manufacturer_encoded\"\n",
    ")\n",
    "encoded_df = manufacturer_encoded.fit(df).transform(df)\n",
    "\n",
    "# Set up our main ML pipeline.\n",
    "columns_to_assemble = [\n",
    "    \"manufacturer_encoded\",\n",
    "    \"cylinders\",\n",
    "    \"displacement\",\n",
    "    \"horsepower\",\n",
    "    \"weight\",\n",
    "    \"acceleration\",\n",
    "]\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=columns_to_assemble,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestRegressor(\n",
    "    numTrees=20,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"mpg\",\n",
    ")\n",
    "\n",
    "# Run the pipeline.\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf])\n",
    "\n",
    "# Hyperparameter search.\n",
    "target_metric = \"rmse\"\n",
    "paramGrid = (\n",
    "    ParamGridBuilder().addGrid(rf.numTrees, list(range(20, 100, 10))).build()\n",
    ")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(\n",
    "        labelCol=\"mpg\", predictionCol=\"prediction\", metricName=target_metric\n",
    "    ),\n",
    "    numFolds=2,\n",
    "    parallelism=4,\n",
    ")\n",
    "\n",
    "# Run cross-validation, get metrics for each parameter.\n",
    "model = crossval.fit(encoded_df)\n",
    "\n",
    "# Plot results using matplotlib.\n",
    "import pandas\n",
    "import matplotlib\n",
    "\n",
    "parameter_grid = [\n",
    "    {k.name: v for k, v in p.items()} for p in model.getEstimatorParamMaps()\n",
    "]\n",
    "pdf = pandas.DataFrame(\n",
    "    model.avgMetrics,\n",
    "    index=[x[\"numTrees\"] for x in parameter_grid],\n",
    "    columns=[target_metric],\n",
    ")\n",
    "ax = pdf.plot(style=\"*-\")\n",
    "ax.figure.suptitle(\"Hyperparameter Search: RMSE by Number of Trees\")\n",
    "ax.figure.savefig(\"hyperparameters.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04938483",
   "metadata": {},
   "source": [
    "**A Random Forest Classification model with Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "002322e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model has 50 trees.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "label_column = \"cover_type\"\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=covtype_df.columns,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "\n",
    "# Define the model.\n",
    "rf = RandomForestClassifier(\n",
    "    numTrees=50,\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=label_column,\n",
    ")\n",
    "\n",
    "# Run the pipeline.\n",
    "pipeline = Pipeline(stages=[vector_assembler, rf])\n",
    "\n",
    "# Hyperparameter search.\n",
    "paramGrid = (\n",
    "    ParamGridBuilder().addGrid(rf.numTrees, list(range(50, 80, 10))).build()\n",
    ")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=MulticlassClassificationEvaluator(\n",
    "        labelCol=label_column, predictionCol=\"prediction\"\n",
    "    ),\n",
    "    numFolds=2,\n",
    "    parallelism=4,\n",
    ")\n",
    "\n",
    "# Run cross-validation and choose the best set of parameters.\n",
    "model = crossval.fit(covtype_df)\n",
    "\n",
    "# Identify the best hyperparameters.\n",
    "real_model = model.bestModel.stages[1]\n",
    "print(\"Best model has {} trees.\".format(real_model.getNumTrees))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345dd224",
   "metadata": {},
   "source": [
    "**Compute correlation matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3aec1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "# Remove non-numeric columns.\n",
    "df = auto_df_fixed.drop(\"carname\")\n",
    "\n",
    "# Assemble all columns except mpg into a vector.\n",
    "feature_columns = list(df.columns)\n",
    "feature_columns.remove(\"mpg\")\n",
    "vector_col = \"features\"\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=feature_columns,\n",
    "    outputCol=vector_col,\n",
    "    handleInvalid=\"skip\",\n",
    ")\n",
    "df_vector = vector_assembler.transform(df).select(vector_col)\n",
    "\n",
    "# Compute the correlation matrix.\n",
    "matrix = Correlation.corr(df_vector, vector_col)\n",
    "corr_array = matrix.collect()[0][\"pearson({})\".format(vector_col)].toArray()\n",
    "\n",
    "# This part is just for pretty-printing.\n",
    "pdf = pandas.DataFrame(\n",
    "    corr_array, index=feature_columns, columns=feature_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34bcda",
   "metadata": {},
   "source": [
    "## A few performance tips and tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b259438",
   "metadata": {},
   "source": [
    "**Get the Spark version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0b159aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.2\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f816f",
   "metadata": {},
   "source": [
    "**Cache a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "475e40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show the default storage level (NONE).\n",
      "Serialized 1x Replicated\n",
      "\n",
      "Change storage level to Memory/Disk via the cache shortcut.\n",
      "Disk Memory Deserialized 1x Replicated\n",
      "\n",
      "Change storage level to the equivalent of cache using an explicit StorageLevel.\n",
      "Disk Memory Deserialized 1x Replicated\n",
      "\n",
      "Set storage level to NONE using an explicit StorageLevel.\n",
      "Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Make some copies of the DataFrame.\n",
    "df1 = auto_df.where(lit(1) > lit(0))\n",
    "df2 = auto_df.where(lit(2) > lit(0))\n",
    "df3 = auto_df.where(lit(3) > lit(0))\n",
    "\n",
    "print(\"Show the default storage level (NONE).\")\n",
    "print(auto_df.storageLevel)\n",
    "\n",
    "print(\"\\nChange storage level to Memory/Disk via the cache shortcut.\")\n",
    "df1.cache()\n",
    "print(df1.storageLevel)\n",
    "\n",
    "print(\n",
    "    \"\\nChange storage level to the equivalent of cache using an explicit StorageLevel.\"\n",
    ")\n",
    "df2.persist(storageLevel=StorageLevel(True, True, False, True, 1))\n",
    "print(df2.storageLevel)\n",
    "\n",
    "print(\"\\nSet storage level to NONE using an explicit StorageLevel.\")\n",
    "df3.persist(storageLevel=StorageLevel(False, False, False, False, 1))\n",
    "print(df3.storageLevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422486a",
   "metadata": {},
   "source": [
    "**Partition by a Column Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329895e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows is an iterable, e.g. itertools.chain\n",
    "def number_in_partition(rows):\n",
    "    try:\n",
    "        first_row = next(rows)\n",
    "        partition_size = sum(1 for x in rows) + 1\n",
    "        partition_value = first_row.modelyear\n",
    "        print(f\"Partition {partition_value} has {partition_size} records\")\n",
    "    except StopIteration:\n",
    "        print(\"Empty partition\")\n",
    "\n",
    "df = auto_df.repartition(20, \"modelyear\")\n",
    "df.foreachPartition(number_in_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b3628",
   "metadata": {},
   "source": [
    "**Range Partition a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f65e869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# rows is an iterable, e.g. itertools.chain\n",
    "def count_in_partition(rows):\n",
    "    my_years = set()\n",
    "    number_in_partition = 0\n",
    "    for row in rows:\n",
    "        my_years.add(row.modelyear)\n",
    "        number_in_partition += 1\n",
    "    seen_years = sorted(list(my_years))\n",
    "    if len(seen_years) > 0:\n",
    "        seen_values = \",\".join(seen_years)\n",
    "        print(\n",
    "            f\"This partition has {number_in_partition} records with years {seen_values}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Empty partition\")\n",
    "\n",
    "number_of_partitions = 5\n",
    "df = auto_df.repartitionByRange(number_of_partitions, col(\"modelyear\"))\n",
    "df.foreachPartition(count_in_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f5b1f",
   "metadata": {},
   "source": [
    "**Change Number of DataFrame Partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "60d48825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|10.0|        8|       360.0|     215.0| 4615.|        14.0|       70|     1|           ford f250|\n",
      "|10.0|        8|       307.0|     200.0| 4376.|        15.0|       70|     1|           chevy c20|\n",
      "|11.0|        8|       318.0|     210.0| 4382.|        13.5|       70|     1|          dodge d200|\n",
      "|16.0|        6|       225.0|     105.0| 3439.|        15.5|       71|     1|plymouth satellit...|\n",
      "|14.0|        8|       350.0|     165.0| 4209.|        12.0|       71|     1|    chevrolet impala|\n",
      "|14.0|        8|       400.0|     175.0| 4464.|        11.5|       71|     1|pontiac catalina ...|\n",
      "|14.0|        8|       351.0|     153.0| 4154.|        13.5|       71|     1|    ford galaxie 500|\n",
      "|14.0|        8|       318.0|     150.0| 4096.|        13.0|       71|     1|   plymouth fury iii|\n",
      "|12.0|        8|       383.0|     180.0| 4955.|        11.5|       71|     1|   dodge monaco (sw)|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = auto_df.repartition(col(\"modelyear\"))\n",
    "number_of_partitions = 5\n",
    "df = auto_df.repartitionByRange(number_of_partitions, col(\"mpg\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25e212",
   "metadata": {},
   "source": [
    "**Coalesce DataFrame partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32f4fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0| 3504.|        12.0|       70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0| 3693.|        11.5|       70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0| 3436.|        11.0|       70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0| 3433.|        12.0|       70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       429.0|     198.0| 4341.|        10.0|       70|     1|    ford galaxie 500|\n",
      "|14.0|        8|       454.0|     220.0| 4354.|         9.0|       70|     1|    chevrolet impala|\n",
      "|14.0|        8|       440.0|     215.0| 4312.|         8.5|       70|     1|   plymouth fury iii|\n",
      "|14.0|        8|       455.0|     225.0| 4425.|        10.0|       70|     1|    pontiac catalina|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|15.0|        8|       383.0|     170.0| 3563.|        10.0|       70|     1| dodge challenger se|\n",
      "|14.0|        8|       340.0|     160.0| 3609.|         8.0|       70|     1|  plymouth 'cuda 340|\n",
      "|15.0|        8|       400.0|     150.0| 3761.|         9.5|       70|     1|chevrolet monte c...|\n",
      "|14.0|        8|       455.0|     225.0| 3086.|        10.0|       70|     1|buick estate wago...|\n",
      "|24.0|        4|       113.0|     95.00| 2372.|        15.0|       70|     3|toyota corona mar...|\n",
      "|22.0|        6|       198.0|     95.00| 2833.|        15.5|       70|     1|     plymouth duster|\n",
      "|18.0|        6|       199.0|     97.00| 2774.|        15.5|       70|     1|          amc hornet|\n",
      "|21.0|        6|       200.0|     85.00| 2587.|        16.0|       70|     1|       ford maverick|\n",
      "|27.0|        4|       97.00|     88.00| 2130.|        14.5|       70|     3|        datsun pl510|\n",
      "|26.0|        4|       97.00|     46.00| 1835.|        20.5|       70|     2|volkswagen 1131 d...|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "target_partitions = math.ceil(auto_df.rdd.getNumPartitions() / 2)\n",
    "df = auto_df.coalesce(target_partitions)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59734187",
   "metadata": {},
   "source": [
    "**Set the number of shuffle partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "92e473be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 partition(s)\n",
      "20 partition(s)\n"
     ]
    }
   ],
   "source": [
    "# Default shuffle partitions is usually 200.\n",
    "grouped1 = auto_df.groupBy(\"cylinders\").count()\n",
    "print(\"{} partition(s)\".format(grouped1.rdd.getNumPartitions()))\n",
    "\n",
    "# Set the shuffle partitions to 20.\n",
    "# This can reduce the number of files generated when saving DataFrames.\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 20)\n",
    "\n",
    "grouped2 = auto_df.groupBy(\"cylinders\").count()\n",
    "print(\"{} partition(s)\".format(grouped2.rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28de287",
   "metadata": {},
   "source": [
    "**Sample a subset of a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f91b8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|modelyear|origin|             carname|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "|17.0|        8|       302.0|     140.0| 3449.|        10.5|       70|     1|         ford torino|\n",
      "|15.0|        8|       390.0|     190.0| 3850.|         8.5|       70|     1|  amc ambassador dpl|\n",
      "|18.0|        6|       232.0|     100.0| 3288.|        15.5|       71|     1|         amc matador|\n",
      "|19.0|        6|       250.0|     100.0| 3282.|        15.0|       71|     1|    pontiac firebird|\n",
      "|30.0|        4|       79.00|     70.00| 2074.|        19.5|       71|     2|         peugeot 304|\n",
      "|31.0|        4|       71.00|     65.00| 1773.|        19.0|       71|     3| toyota corolla 1200|\n",
      "|14.0|        8|       351.0|     153.0| 4129.|        13.0|       72|     1|    ford galaxie 500|\n",
      "|14.0|        8|       318.0|     150.0| 4077.|        14.0|       72|     1|plymouth satellit...|\n",
      "|21.0|        4|       120.0|     87.00| 2979.|        19.5|       72|     2|    peugeot 504 (sw)|\n",
      "|12.0|        8|       429.0|     198.0| 4952.|        11.5|       73|     1|mercury marquis b...|\n",
      "|18.0|        6|       232.0|     100.0| 2945.|        16.0|       73|     1|          amc hornet|\n",
      "|18.0|        6|       250.0|     88.00| 3021.|        16.5|       73|     1|       ford maverick|\n",
      "|20.0|        4|       97.00|     88.00| 2279.|        19.0|       73|     3|       toyota carina|\n",
      "|19.0|        4|       122.0|     85.00| 2310.|        18.5|       73|     1|          ford pinto|\n",
      "|29.0|        4|       68.00|     49.00| 1867.|        19.5|       73|     2|            fiat 128|\n",
      "|20.0|        4|       114.0|     91.00| 2582.|        14.0|       73|     2|          audi 100ls|\n",
      "|19.0|        6|       232.0|     100.0| 2901.|        16.0|       74|     1|          amc hornet|\n",
      "|26.0|        4|       79.00|     67.00| 1963.|        15.5|       74|     2|   volkswagen dasher|\n",
      "|24.0|        4|       120.0|     97.00| 2489.|        15.0|       74|     3|         honda civic|\n",
      "|23.0|        4|       140.0|     83.00| 2639.|        17.0|       75|     1|          ford pinto|\n",
      "+----+---------+------------+----------+------+------------+---------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(\"data/auto-mpg.csv\")\n",
    "    .sample(0.1)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33505a9f",
   "metadata": {},
   "source": [
    "**Print Spark configuration properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1d828875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.initial.jar.urls', 'spark://host.docker.internal:55380/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,spark://host.docker.internal:55380/jars/io.delta_delta-core_2.12-1.0.0.jar,spark://host.docker.internal:55380/jars/org.antlr_ST4-4.0.8.jar,spark://host.docker.internal:55380/jars/com.ibm.icu_icu4j-58.2.jar,spark://host.docker.internal:55380/jars/org.antlr_antlr4-4.7.jar,spark://host.docker.internal:55380/jars/org.antlr_antlr-runtime-3.5.2.jar,spark://host.docker.internal:55380/jars/org.glassfish_javax.json-1.0.4.jar,spark://host.docker.internal:55380/jars/org.antlr_antlr4-runtime-4.7.jar'), ('spark.driver.host', 'host.docker.internal'), ('spark.driver.memory', '2G'), ('spark.app.id', 'local-1634272078414'), ('spark.master', 'local[4]'), ('spark.submit.pyFiles', 'C:/Users/shubh/.ivy2/jars/io.delta_delta-core_2.12-1.0.0.jar,C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-4.7.jar,C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,C:/Users/shubh/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,C:/Users/shubh/.ivy2/jars/org.antlr_ST4-4.0.8.jar,C:/Users/shubh/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,C:/Users/shubh/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,C:/Users/shubh/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.executor.memory', '2G'), ('spark.executor.id', 'driver'), ('spark.files', 'file:///C:/Users/shubh/.ivy2/jars/io.delta_delta-core_2.12-1.0.0.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///C:/Users/shubh/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///C:/Users/shubh/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///C:/Users/shubh/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.app.initial.file.urls', 'file:///C:/Users/shubh/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///C:/Users/shubh/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///C:/Users/shubh/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/io.delta_delta-core_2.12-1.0.0.jar'), ('spark.sql.catalogImplementation', 'hive'), ('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension'), ('spark.app.startTime', '1634272076488'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.submit.deployMode', 'client'), ('spark.repl.local.jars', 'file:///C:/Users/shubh/.ivy2/jars/io.delta_delta-core_2.12-1.0.0.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///C:/Users/shubh/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///C:/Users/shubh/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///C:/Users/shubh/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.app.name', 'cheatsheet'), ('spark.driver.port', '55380'), ('spark.ui.showConsoleProgress', 'true'), ('spark.jars', 'file:///C:/Users/shubh/.ivy2/jars/io.delta_delta-core_2.12-1.0.0.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr4-runtime-4.7.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_antlr-runtime-3.5.2.jar,file:///C:/Users/shubh/.ivy2/jars/org.antlr_ST4-4.0.8.jar,file:///C:/Users/shubh/.ivy2/jars/org.abego.treelayout_org.abego.treelayout.core-1.0.3.jar,file:///C:/Users/shubh/.ivy2/jars/org.glassfish_javax.json-1.0.4.jar,file:///C:/Users/shubh/.ivy2/jars/com.ibm.icu_icu4j-58.2.jar'), ('spark.jars.packages', 'io.delta:delta-core_2.12:1.0.0'), ('spark.sql.warehouse.dir', 'C:\\\\Users\\\\shubh\\\\Desktop\\\\pyspark-cheatsheet\\\\spark-warehouse'), ('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog')]\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e2a68",
   "metadata": {},
   "source": [
    "**Increase Spark driver/executor heap space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0790330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory configuration depends entirely on your runtime.\n",
    "# In OCI Data Flow you control memory by selecting a larger or smaller VM.\n",
    "# No other configuration is needed.\n",
    "#\n",
    "# For other environments see the Spark \"Cluster Mode Overview\" to get started.\n",
    "# https://spark.apache.org/docs/latest/cluster-overview.html\n",
    "# And good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce806a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
